#
# This script is Copyright (C) 2004-2020 and is owned by Tenable, Inc. or an Affiliate thereof.
#
# This script is released under the Tenable Subscription License and
# may not be used from within scripts released under another license
# without authorization from Tenable, Inc.
#
# See the following licenses for details:
#
# http://static.tenable.com/prod_docs/Nessus_6_SLA_and_Subscription_Agreement.pdf
#
# @PROFESSIONALFEED@
# $Revision: 1.10 $
# $Date: 2020/07/14 $
#
# description			: This .audit is designed against the CIS Docker 1.12.0 Benchmark v1.0.0 - 08-15-2016.
#
# 	https://workbench.cisecurity.org/files/517
#
# Many commands use unqualified paths to be flexible in executing on different docker vessel linux distributions
#
#<ui_metadata>
#<display_name>CIS Docker 1.12.0 v1.0.0 L1 Docker</display_name>
#<spec>
#  <type>CIS</type>
#  <name>Docker 1.12.0 L1 Docker</name>
#  <version>1.0.0</version>
#  <link>https://workbench.cisecurity.org/files/517</link>
#</spec>
#<labels>unix,cis,docker,agent</labels>
#<benchmark_refs>LEVEL</benchmark_refs>
#<variables>
#  <variable>
#    <name>BASE_PATH_TO_CERTS</name>
#    <default>/etc/docker/certs.d/</default>
#    <description>Base Path to Certs</description>
#    <info>Base Path to Certs - include trailing /</info>
#  </variable>
#  <variable>
#    <name>DEFAULT_ULIMIT</name>
#    <default>nofile=1024:1024</default>
#    <description>--default-ulimit</description>
#    <info>Docker Daemon --default-ulimit settings</info>
#  </variable>
#  <variable>
#    <name>PATH_TO_SERVER_CERT_FILE</name>
#    <default>/etc/docker/certs.d/DOCKER_SERVER_CERT</default>
#    <description>Docker Server Cert file path</description>
#    <info>Docker Server Cert file path</info>
#  </variable>
#  <variable>
#    <name>PATH_TO_SERVER_CERT_KEY_FILE</name>
#    <default>/etc/docker/certs.d/DOCKER_SERVER_CERT_KEY</default>
#    <description>Docker Server Cert key file path</description>
#    <info>Docker Server Cert key file path</info>
#  </variable>
#  <variable>
#    <name>PATH_TO_DOCKER_SERVICE_FILE</name>
#    <default>/usr/lib/systemd/system/docker.service</default>
#    <description>Path to docker.service file</description>
#    <info>3.1 - Path to docker.service file</info>
#  </variable>
#  <variable>
#    <name>PATH_TO_DOCKER_SOCKET_FILE</name>
#    <default>/usr/lib/systemd/system/docker.socket</default>
#    <description>Path to docker.socket file</description>
#    <info>3.3 - Path to docker.socket file</info>
#  </variable>
#  <variable>
#    <name>PATH_TO_TLS_CA_FILE</name>
#    <default>/etc/docker/certs.d/CA_CERT</default>
#    <description>CA Cert file path</description>
#    <info>CA Cert file path</info>
#  </variable>
#  <variable>
#    <name>REGISTRY_NAME</name>
#    <default>default_registry</default>
#    <description>Registry Name</description>
#    <info>Registry Name for use in file path - 3.16 and 3.17</info>
#  </variable>
#</variables>
#</ui_metadata>

<check_type:"Unix">

<if>
  <condition type:"AND">
    <custom_item>
      type        : CMD_EXEC
      description : "Check if this is a Docker Vessel/Host"
      cmd         : "/usr/bin/docker info"
      expect      : "Containers"
    </custom_item>
  </condition>

  <then>
    <report type:"PASSED">
      description : "CIS_Docker_1.12.0_v1.0.0_L1.audit Level 1"
    </report>

    <custom_item>
      type        : CMD_EXEC
      description : "2.1 Restrict network traffic between containers"
      info        : "By default, all network traffic is allowed between containers on the same host. If not
desired, restrict all the inter container communication. Link specific containers together
that require inter communication.By default, unrestricted network traffic is enabled between all containers on the same host.
Thus, each container has the potential of reading all packets across the container network
on the same host. This might lead to unintended and unwanted disclosure of information to
other containers. Hence, restrict the inter container communication."
      info        : "https://docs.docker.com/articles/networking"
      solution    : "Run the docker in daemon mode and pass '--icc=false' as argument.For Example,/usr/bin/dockerd --icc=false
Impact-The inter container communication would be disabled. No containers would be able to talk
to another container on the same host. If any communication between containers on the
same host is desired, then it needs to be explicitly defined using container linking.Default Value-By default, all inter container communication is allowed."
      reference   : "800-171|3.13.2,800-171|3.13.5,800-53|SC-7(21),CSF|PR.AC-5,CSF|PR.DS-5,LEVEL|1S,NESA|T4.5.3,NIAv2|VL6"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [i]cc="
      expect      : "icc=false"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.2 Set the logging level"
      info        : "Set Docker daemon log level to 'info'.Setting up an appropriate log level, configures the Docker daemon to log events that you
would want to review later. A base log level of 'info' and above would capture all logs
except debug logs. Until and unless required, you should not run Docker daemon at 'debug'
log level."
      info        : "https://docs.docker.com/engine/reference/commandline/daemon/"
      solution    : "Run the Docker daemon as below-dockerd --log-level='info'Impact-None.Default Value-By default, Docker daemon is set to log level of 'info'."
      reference   : "800-171|3.3.1,800-171|3.3.2,800-53|AU-3,CN-L3|7.1.2.3(a),CN-L3|7.1.2.3(b),CN-L3|7.1.3.3(a),CN-L3|8.1.4.3(b),CSF|PR.PT-1,ITSG-33|AU-3,LEVEL|1S,NESA|T3.6.2,NIAv2|AM34a,NIAv2|AM34b,NIAv2|AM34c,NIAv2|AM34d,NIAv2|AM34e,NIAv2|AM34f,NIAv2|AM34g,SWIFT-CSCv1|6.4"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [l]og-level"
      expect      : "log-level='info'"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.3 Allow Docker to make changes to iptables"
      info        : "Iptables are used to set up, maintain, and inspect the tables of IP packet filter rules in the
Linux kernel. Allow the Docker daemon to make changes to the iptables.Docker will never make changes to your system iptables rules if you choose to do so.
Docker server would automatically make the needed changes to iptables based on how you
choose your networking options for the containers if it is allowed to do so. It is
recommended to let Docker server make changes to iptables automatically to avoid
networking misconfiguration that might hamper the communication between containers
and to the outside world. Additionally, it would save you hassles of updating iptables
every time you choose to run the containers or modify networking options."
      info        : "https://docs.docker.com/v1.8/articles/networking/"
      solution    : "Do not run the Docker daemon with '--iptables=false' parameter.
For example, do not start the Docker daemon as below-dockerd --iptables=falseImpact-None.Default Value-By default, 'iptables' is set to 'true'."
      reference   : "800-171|3.13.1,800-53|SC-7(12),ITSG-33|SC-7(12),LEVEL|1S,NIAv2|AM38,NIAv2|SS13d,NIAv2|SS26"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [i]ptables=false | /usr/bin/awk '{print} END {if (NR == 0) print \"none\"}'"
      expect      : "none"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.4 Do not use insecure registries"
      info        : "Docker considers a private registry either secure or insecure. By default, registries are
considered secure.A secure registry uses TLS. A copy of registry's CA certificate is placed on the Docker host at
'/etc/docker/certs.d/<registry-name>/' directory. An insecure registry is the one not
having either valid registry certificate or is not using TLS. You should not be using any
insecure registries in the production environment. Insecure registries can be tampered
with leading to possible compromise to your production system.Additionally, If a registry is marked as insecure then 'docker pull', 'docker push', and
'docker search' commands will not result in an error message and the user might be
indefinitely working with insecure registries without ever being notified of potential
danger."
      info        : "https://docs.docker.com/registry/insecure/"
      solution    : "Do not use any insecure registries.For example, do not start the Docker daemon as below-dockerd --insecure-registry 10.1.0.0/16Impact-None.
Default Value-By default, Docker assumes all, but local, registries are secure."
      reference   : "800-53|SI-7(6),CSF|PR.DS-6,LEVEL|1S,SWIFT-CSCv1|6.2"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [i]nsecure-registry | /usr/bin/awk '{print} END {if (NR == 0) print \"none\"}'"
      expect      : "none"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.5 Do not use the aufs storage driver"
      info        : "Do not use 'aufs' as storage driver for your Docker instance.The 'aufs' storage driver is the oldest storage driver. It is based on a Linux kernel patch-set
that is unlikely to be merged into the main Linux kernel. 'aufs' driver is also known to
cause some serious kernel crashes. 'aufs' just has legacy support from Docker. Most
importantly, 'aufs' is not a supported driver in many Linux distributions using latest Linux
kernels."
      info        : "http://docs.docker.com/reference/commandline/cli/#daemon-storage-driver-option
2.https://github.com/docker/docker/issues/6047
3.http://muehe.org/posts/switching-docker-from-aufs-to-devicemapper/
4.http://jpetazzo.github.io/assets/2015-03-05-deep-dive-into-docker-storage-drivers.html#1"
      solution    : "Do not explicitly use 'aufs' as storage driver.For example, do not start Docker daemon as below-dockerd --storage-driver aufsImpact-'aufs' is the only storage driver that allows containers to share executable and shared
library memory. It might be useful if you are running thousands of containers with the
same program or libraries.
Default Value-By default, Docker uses 'devicemapper' as the storage driver on most of the platforms.
Default storage driver can vary based on your OS vendor. You should use the storage driver
that is best supported by your preferred vendor."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker info | grep -ie \"^storage driver: aufs\" | /usr/bin/awk '{print} END {if (NR == 0) print \"none\"}'"
      expect      : "none"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.6 Configure TLS authentication for Docker daemon - tlscacert"
      info        : "It is possible to make the Docker daemon to listen on a specific IP and port and any other
Unix socket other than default Unix socket. Configure TLS authentication to restrict access
to Docker daemon via IP and port.By default, Docker daemon binds to a non-networked Unix socket and runs with 'root'
privileges. If you change the default docker daemon binding to a TCP port or any other Unix
socket, anyone with access to that port or socket can have full access to Docker daemon
and in turn to the host system. Hence, you should not bind the Docker daemon to another
IP/port or a Unix socket.If you must expose the Docker daemon via a network socket, configure TLS authentication
for the daemon and Docker Swarm APIs (if using). This would restrict the connections to
your Docker daemon over the network to a limited number of clients who could
successfully authenticate over TLS."
      info        : "http://docs.docker.com/articles/https/
2.http://www.hnwatcher.com/r/1644394/Intro-to-Docker-Swarm-Part-2-Comfiguration-Modes-and-Requirements
3.http://www.blackfinsecurity.com/docker-swarm-with-tls-authentication/"
      solution    : "Follow the steps mentioned in the Docker documentation or other references.Impact-You would need to manage and guard certificates and keys for Docker daemon and Docker
clients.
Default Value-By default, TLS authentication is not configured."
      reference   : "800-171|3.13.11,800-53|SC-13,CSF|PR.DS-5,ISO/IEC-27001|A.10.1.1,ITSG-33|SC-13,LEVEL|1S,NESA|M5.2.6,NESA|T7.4.1,NIAv2|CY3,NIAv2|CY4,NIAv2|CY5b,NIAv2|CY5c,NIAv2|CY5d,NIAv2|CY7,NIAv2|NS5e"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]tlscacert"
      expect      : "--tlscacert"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.6 Configure TLS authentication for Docker daemon -tlsverify"
      info        : "It is possible to make the Docker daemon to listen on a specific IP and port and any other
Unix socket other than default Unix socket. Configure TLS authentication to restrict access
to Docker daemon via IP and port.By default, Docker daemon binds to a non-networked Unix socket and runs with 'root'
privileges. If you change the default docker daemon binding to a TCP port or any other Unix
socket, anyone with access to that port or socket can have full access to Docker daemon
and in turn to the host system. Hence, you should not bind the Docker daemon to another
IP/port or a Unix socket.If you must expose the Docker daemon via a network socket, configure TLS authentication
for the daemon and Docker Swarm APIs (if using). This would restrict the connections to
your Docker daemon over the network to a limited number of clients who could
successfully authenticate over TLS."
      info        : "http://docs.docker.com/articles/https/
2.http://www.hnwatcher.com/r/1644394/Intro-to-Docker-Swarm-Part-2-Comfiguration-Modes-and-Requirements
3.http://www.blackfinsecurity.com/docker-swarm-with-tls-authentication/"
      solution    : "Follow the steps mentioned in the Docker documentation or other references.Impact-You would need to manage and guard certificates and keys for Docker daemon and Docker
clients.
Default Value-By default, TLS authentication is not configured."
      reference   : "800-171|3.13.11,800-53|SC-13,CSF|PR.DS-5,ISO/IEC-27001|A.10.1.1,ITSG-33|SC-13,LEVEL|1S,NESA|M5.2.6,NESA|T7.4.1,NIAv2|CY3,NIAv2|CY4,NIAv2|CY5b,NIAv2|CY5c,NIAv2|CY5d,NIAv2|CY7,NIAv2|NS5e"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]tlsverify"
      expect      : "--tlsverify"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.6 Configure TLS authentication for Docker daemon - tlskey"
      info        : "It is possible to make the Docker daemon to listen on a specific IP and port and any other
Unix socket other than default Unix socket. Configure TLS authentication to restrict access
to Docker daemon via IP and port.By default, Docker daemon binds to a non-networked Unix socket and runs with 'root'
privileges. If you change the default docker daemon binding to a TCP port or any other Unix
socket, anyone with access to that port or socket can have full access to Docker daemon
and in turn to the host system. Hence, you should not bind the Docker daemon to another
IP/port or a Unix socket.If you must expose the Docker daemon via a network socket, configure TLS authentication
for the daemon and Docker Swarm APIs (if using). This would restrict the connections to
your Docker daemon over the network to a limited number of clients who could
successfully authenticate over TLS."
      info        : "http://docs.docker.com/articles/https/
2.http://www.hnwatcher.com/r/1644394/Intro-to-Docker-Swarm-Part-2-Comfiguration-Modes-and-Requirements
3.http://www.blackfinsecurity.com/docker-swarm-with-tls-authentication/"
      solution    : "Follow the steps mentioned in the Docker documentation or other references.Impact-You would need to manage and guard certificates and keys for Docker daemon and Docker
clients.
Default Value-By default, TLS authentication is not configured."
      reference   : "800-171|3.13.11,800-53|SC-13,CSF|PR.DS-5,ISO/IEC-27001|A.10.1.1,ITSG-33|SC-13,LEVEL|1S,NESA|M5.2.6,NESA|T7.4.1,NIAv2|CY3,NIAv2|CY4,NIAv2|CY5b,NIAv2|CY5c,NIAv2|CY5d,NIAv2|CY7,NIAv2|NS5e"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]tlskey"
      expect      : "--tlskey"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.6 Configure TLS authentication for Docker daemon - tlscert"
      info        : "It is possible to make the Docker daemon to listen on a specific IP and port and any other
Unix socket other than default Unix socket. Configure TLS authentication to restrict access
to Docker daemon via IP and port.By default, Docker daemon binds to a non-networked Unix socket and runs with 'root'
privileges. If you change the default docker daemon binding to a TCP port or any other Unix
socket, anyone with access to that port or socket can have full access to Docker daemon
and in turn to the host system. Hence, you should not bind the Docker daemon to another
IP/port or a Unix socket.If you must expose the Docker daemon via a network socket, configure TLS authentication
for the daemon and Docker Swarm APIs (if using). This would restrict the connections to
your Docker daemon over the network to a limited number of clients who could
successfully authenticate over TLS."
      info        : "http://docs.docker.com/articles/https/
2.http://www.hnwatcher.com/r/1644394/Intro-to-Docker-Swarm-Part-2-Comfiguration-Modes-and-Requirements
3.http://www.blackfinsecurity.com/docker-swarm-with-tls-authentication/"
      solution    : "Follow the steps mentioned in the Docker documentation or other references.Impact-You would need to manage and guard certificates and keys for Docker daemon and Docker
clients.
Default Value-By default, TLS authentication is not configured."
      reference   : "800-171|3.13.11,800-53|SC-13,CSF|PR.DS-5,ISO/IEC-27001|A.10.1.1,ITSG-33|SC-13,LEVEL|1S,NESA|M5.2.6,NESA|T7.4.1,NIAv2|CY3,NIAv2|CY4,NIAv2|CY5b,NIAv2|CY5c,NIAv2|CY5d,NIAv2|CY7,NIAv2|NS5e"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]tlscert"
      expect      : "--tlscert"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.7 Set default ulimit as appropriate - default-ulimit"
      info        : "Set the default ulimit options as appropriate in your environment.ulimit provides control over the resources available to the shell and to processes started
by it. Setting system resource limits judiciously saves you from many disasters such as
a fork bomb. Sometimes, even friendly users and legitimate processes can overuse system
resources and in-turn can make the system unusable.Setting default ulimit for the Docker daemon would enforce the ulimit for all container
instances. You would not need to setup ulimit for each container instance. However, the
default ulimit can be overridden during container runtime, if needed. Hence, to control the
system resources, define a default ulimit as needed in your environment."
      info        : "https://docs.docker.com/engine/reference/commandline/daemon/#default-ulimits"
      solution    : "Run the docker in daemon mode and pass '--default-ulimit' as argument with respective
ulimits as appropriate in your environment.For Example,dockerd --default-ulimit nproc=1024-2408 --default-ulimit nofile=100-200Impact-If the ulimits are not set properly, the desired resource control might not be achieved and
might even make the system unusable.Default Value-By default, no ulimit is set."
      reference   : "800-53|SC-6,CN-L3|7.1.3.7(c),CN-L3|7.1.3.7(d),ITSG-33|SC-6,LEVEL|1NS"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]default-ulimit"
# Note: Variable @DEFAULT_ULIMIT@ replaced with "nofile=1024:1024" in field "expect".
      expect      : "--default-ulimit nofile=1024:1024"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.13 Disable operations on legacy registry (v1)"
      info        : "The latest Docker registry is v2. All operations on the legacy registry version (v1) should be
restricted.Docker registry v2 brings in many performance and security improvements over v1. It
supports container image provenance and other security features such as image signing
and verification. Hence, operations on Docker legacy registry should be restricted."
      info        : "https://docs.docker.com/engine/reference/commandline/daemon/
2.https://github.com/docker/docker/issues/8093
3.https://github.com/docker/docker/issues/9015
4.https://github.com/docker/docker-registry/issues/612
5.https://docs.docker.com/registry/spec/api/
6.https://the.binbashtheory.com/creating-private-docker-registry-2-0-with-token-authentication-service/
7.https://blog.docker.com/2015/07/new-tool-v1-registry-docker-trusted-registry-v2-open-source/
8.http://www.slideshare.net/Docker/docker-registry-v2"
      solution    : "Start the docker daemon as below-dockerd --disable-legacy-registryImpact-Legacy registry operations would be restricted.Default Value-By default, legacy registry operations are allowed."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]disable-legacy-registry"
      expect      : "--disable-legacy-registry=false"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.14 Enable live restore"
      info        : "The '--live-restore' enables full support of daemon-less containers in docker. It ensures
that docker does not stop containers on shutdown or restore and properly reconnects to
the container when restarted.One of the important security triads is availability. Setting '--live-restore' flag in the
docker daemon ensures that container execution is not interrupted when the docker
daemon is not available. This also means that it is now easier to update and patch the
docker daemon without execution downtime."
      info        : "https://github.com/docker/docker/pull/23213"
      solution    : "Run the docker in daemon mode and pass '--live-restore' as an argument.For Example,dockerd --live-restoreImpact-None.Default Value-By default, --live-restore is not enabled."
      reference   : "800-53|SC-6,CN-L3|7.1.3.7(c),CN-L3|7.1.3.7(d),ITSG-33|SC-6,LEVEL|1S"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]live-restore"
      expect      : "--live-restore"
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.15 Do not enable swarm mode, if not needed"
      info        : "Do not enable swarm mode on a docker engine instance unless needed.By default, a Docker engine instance will not listen on any network ports, with all
communications with the client coming over the Unix socket. When Docker swarm mode is
enabled on a docker engine instance, multiple network ports are opened on the system and
made available to other systems on the network for the purposes of cluster management
and node communications.Opening network ports on a system increase its attack surface and this should be avoided
unless required.
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      info        : "https://docs.docker.com/engine/reference/commandline/swarm_init/"
      solution    : "If swarm mode has been enabled on a system in error, rundocker swarm leaveImpact-None.Default Value-By default, docker swarm mode is not enabled."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker info |grep Swarm"
      expect      : "Swarm:"
      severity    : MEDIUM
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.16 Control the number of manager nodes in a swarm"
      info        : "Ensure that the minimum number of required manager nodes is created in a swarm.Manager nodes within a swarm have control over the swarm and change its configuration
modifying security parameters. Having excessive manager nodes could render the swarm
more susceptible to compromise.If fault tolerance is not required in the manager nodes, a single node should be elected as
a manger. If fault tolerance is required, then the smallest practical odd number to achieve
the appropriate level of tolerance should be configured.
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      info        : "https://docs.docker.com/engine/swarm/manage-nodes/
2.https://docs.docker.com/engine/swarm/admin_guide/#/add-manager-nodes-for-
fault-tolerance
Note: Nessus has not performed an evaluation of this check. Please manually review the check output
for correctness."
      solution    : "If an excessive number of managers is configured, the excess can be demoted as worker
using the following command-docker node demote <ID>Where <ID> is the node ID value of the manager to be demoted.Impact-NoneDefault Value-A single manager is all that is required to start a given cluster."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker node ls | grep Leader"
      expect      : ".*"
      severity    : MEDIUM
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.17 Bind swarm services to a specific host interface"
      info        : "By default, the docker swarm services will listen to all interfaces on the host, which may
not be necessary for the operation of the swarm where the host has multiple network
interfaces.When a swarm is initialized the default value for the --listen-addr flag is 0.0.0.0:2377
which means that the swarm services will listen on all interfaces on the host. If a host has
multiple network interfaces this may be undesirable as it may expose the docker swarm
services to networks which are not involved in the operation of the swarm.By passing a specific IP address to the --listen-addr, a specific network interface can be
specified limiting this exposure."
      info        : "https://docs.docker.com/engine/reference/commandline/swarm_init/#/listen-
addr-value
2.https://docs.docker.com/engine/swarm/admin_guide/#/recover-from-disaster
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Remediation of this requires re-initialization of the swarm specifying a specific interface
for the --listen-addr parameter.Impact-NoneDefault Value-By default, docker swarm services listen on all available host interfaces."
      reference   : "800-171|3.13.2,800-171|3.13.5,800-53|SC-7(13),CN-L3|8.1.10.6(h),CSF|PR.AC-5,CSF|PR.PT-4,ITSG-33|SC-7(13),LEVEL|1S,NIAv2|GS7d,SWIFT-CSCv1|3.1"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ss -nlp|grep dockerd"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "2.18 Disable Userland Proxy"
      info        : "The docker daemon starts a userland proxy service for port forwarding whenever a port is
exposed. Where hairpin NAT is available, this service is generally superfluous to
requirements and can be disabled.Docker engine provides two mechanisms for forwarding ports from the host to containers,
hairpin NAT, and a userland proxy. In most circumstances, the hairpin NAT mode is
preferred as it improves performance and makes use of native Linux iptables functionality
instead of an additional component.Where hairpin NAT is available, the userland proxy should be disabled on startup to reduce
the attack surface of the installation."
      info        : "http://windsock.io/the-docker-proxy/
2.https://github.com/docker/docker/issues/14856
3.https://github.com/docker/docker/issues/22741
4.https://docs.docker.com/engine/userguide/networking/default_network/binding/"
      solution    : "Run the Docker daemon as below-dockerd --userland-proxy=falseImpact-Some systems with older Linux kernels may not be able to support hairpin NAT and
therefore require the userland proxy service. Also, some networking setups can be
impacted by the removal of the userland proxy.Default Value-By default, the userland proxy is enabled."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "ps -ef | grep docker | grep [\-][\-]userland-proxy"
      expect      : "--userland-proxy=false"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.1 Verify that docker.service file ownership is set to root:root"
      info        : "Verify that the 'docker.service' file ownership and group-ownership are correctly set to
'root'.'docker.service' file contains sensitive parameters that may alter the behavior of Docker
daemon. Hence, it should be owned and group-owned by 'root' to maintain the integrity of
the file."
      info        : "https://docs.docker.com/engine/admin/systemd/"
      solution    : "Step 1- Find out the file location-systemctl show -p FragmentPath docker.service
Step 2- If the file does not exist, this recommendation is not applicable. If the file exists,
execute the below command with the correct file path to set the ownership and group
ownership for the file to 'root'.For example,chown root-root /usr/lib/systemd/system/docker.serviceImpact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable. By default, if the file is present, the ownership and group-ownership for this file
is correctly set to 'root'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_DOCKER_SERVICE_FILE@ replaced with "/usr/lib/systemd/system/docker.service" in field "file".
      file        : "/usr/lib/systemd/system/docker.service"
      owner       : "root"
      required    : NO
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.2 Verify that docker.service file permissions are set to 644 or more restrictive"
      info        : "Verify that the 'docker.service' file permissions are correctly set to '644' or more
restrictive.'docker.service' file contains sensitive parameters that may alter the behavior of Docker
daemon. Hence, it should not be writable by any other user other than 'root' to maintain
the integrity of the file."
      info        : "https://docs.docker.com/articles/systemd/"
      solution    : "Step 1- Find out the file location-systemctl show -p FragmentPath docker.serviceStep 2- If the file does not exist, this recommendation is not applicable. If the file exists,
execute the below command with the correct file path to set the file permissions to '644'.For example,chmod 644 /usr/lib/systemd/system/docker.service
Impact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable. By default, if the file is present, the file permissions are correctly set to '644'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_DOCKER_SERVICE_FILE@ replaced with "/usr/lib/systemd/system/docker.service" in field "file".
      file        : "/usr/lib/systemd/system/docker.service"
      mask        : "133"
      required    : NO
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.3 Verify that docker.socket file ownership is set to root:root"
      info        : "Verify that the 'docker.socket' file ownership and group ownership is correctly set to
'root'.'docker.socket' file contains sensitive parameters that may alter the behavior of Docker
remote API. Hence, it should be owned and group-owned by 'root' to maintain the integrity
of the file."
      info        : "https://docs.docker.com/articles/basics/#bind-docker-to-another-hostport-or-a-unix-socket
2.https://github.com/YungSang/fedora-atomic-packer/blob/master/oem/docker.socket
3.http://daviddaeschler.com/2014/12/14/centos-7rhel-7-and-docker-containers-on-boot/"
      solution    : "Step 1- Find out the file location-systemctl show -p FragmentPath docker.socketStep 2- If the file does not exist, this recommendation is not applicable. If the file exists,
execute the below command with the correct file path to set the ownership and group
ownership for the file to 'root'.For example,
chown root-root /usr/lib/systemd/system/docker.socketImpact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable. By default, if the file is present, the ownership and group-ownership for this file
is correctly set to 'root'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_DOCKER_SOCKET_FILE@ replaced with "/usr/lib/systemd/system/docker.socket" in field "file".
      file        : "/usr/lib/systemd/system/docker.socket"
      owner       : "root"
      required    : NO
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.4 Verify that docker.socket file permissions are set to 644 or more restrictive"
      info        : "Verify that the 'docker.socket' file permissions are correctly set to '644' or more
restrictive.'docker.socket' file contains sensitive parameters that may alter the behavior of Docker
remote API. Hence, it should be writable only by 'root' to maintain the integrity of the file."
      info        : "https://docs.docker.com/articles/basics/#bind-docker-to-another-hostport-or-a-unix-socket
2.https://github.com/YungSang/fedora-atomic-packer/blob/master/oem/docker.socket
3.http://daviddaeschler.com/2014/12/14/centos-7rhel-7-and-docker-containers-on-boot/"
      solution    : "Step 1- Find out the file location-systemctl show -p FragmentPath docker.socketStep 2- If the file does not exist, this recommendation is not applicable. If the file exists,
execute the below command with the correct file path to set the file permissions to '644'.For example,chmod 644 /usr/lib/systemd/system/docker.socket
Impact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable. By default, if the file is present, the file permissions for this file are correctly set
to '644'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_DOCKER_SOCKET_FILE@ replaced with "/usr/lib/systemd/system/docker.socket" in field "file".
      file        : "/usr/lib/systemd/system/docker.socket"
      mask        : "133"
      required    : NO
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.5 Verify that /etc/docker directory ownership is set to root:root"
      info        : "Verify that the /etc/docker directory ownership and group-ownership is correctly set to
'root'.'/etc/docker' directory contains certificates and keys in addition to various sensitive files.
Hence, it should be owned and group-owned by 'root' to maintain the integrity of the
directory."
      info        : "https://docs.docker.com/articles/certificates/"
      solution    : "chown root-root /etc/dockerThis would set the ownership and group-ownership for the directory to 'root'.Impact-None.Default Value-By default, the ownership and group-ownership for this directory is correctly set to 'root'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/etc/docker"
      owner       : "root"
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.6 Verify that /etc/docker directory permissions are set to 755 or more restrictive"
      info        : "Verify that the /etc/docker directory permissions are correctly set to '755' or more
restrictive.'/etc/docker' directory contains certificates and keys in addition to various sensitive files.
Hence, it should only be writable by 'root' to maintain the integrity of the directory."
      info        : "https://docs.docker.com/articles/certificates/"
      solution    : "chmod 755 /etc/dockerThis would set the permissions for the directory to '755'.Impact-None.Default Value-By default, the permissions for this directory are correctly set to '755'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/etc/docker"
      mask        : "022"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.7 Verify that registry certificate file ownership is set to root:root"
      info        : "Verify that all the registry certificate files (usually found
under /etc/docker/certs.d/<registry-name> directory) are owned and group-owned by
'root'./etc/docker/certs.d/<registry-name> directory contains Docker registry certificates.
These certificate files must be owned and group-owned by 'root' to maintain the integrity
of the certificates."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/reference/commandline/cli/#insecure-registries"
      solution    : "chown root-root /etc/docker/certs.d/<registry-name>/*
This would set the ownership and group-ownership for the registry certificate files to
'root'.Impact-None.Default Value-By default, the ownership and group-ownership for registry certificate files is correctly set
to 'root'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @BASE_PATH_TO_CERTS@ replaced with "/etc/docker/certs.d/" in field "file".
# Note: Variable @REGISTRY_NAME@ replaced with "default_registry" in field "file".
      file        : "/etc/docker/certs.d/default_registry/*"
      owner       : "root"
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.8 Verify that registry certificate file permissions are set to 444 or more restrictive"
      info        : "Verify that all the registry certificate files (usually found
under /etc/docker/certs.d/<registry-name> directory) have permissions of '444' or
more restrictive./etc/docker/certs.d/<registry-name> directory contains Docker registry certificates.
These certificate files must have permissions of '444' to maintain the integrity of the
certificates."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/reference/commandline/cli/#insecure-registries"
      solution    : "chmod 444 /etc/docker/certs.d/<registry-name>/*
This would set the permissions for registry certificate files to '444'.Impact-None.Default Value-By default, the permissions for registry certificate files might not be '444'. The default file
permissions are governed by the system or user specific umask values."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @BASE_PATH_TO_CERTS@ replaced with "/etc/docker/certs.d/" in field "file".
# Note: Variable @REGISTRY_NAME@ replaced with "default_registry" in field "file".
      file        : "/etc/docker/certs.d/default_registry/*"
      mask        : "333"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.9 Verify that TLS CA certificate file ownership is set to root:root"
      info        : "Verify that the TLS CA certificate file (the file that is passed alongwith '--
tlscacert' parameter) is owned and group-owned by 'root'.The TLS CA certificate file should be protected from any tampering. It is used to
authenticate Docker server based on given CA certificate. Hence, it must be owned and
group-owned by 'root' to maintain the integrity of the CA certificate."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/articles/https/"
      solution    : "chown root-root <path to TLS CA certificate file>
This would set the ownership and group-ownership for the TLS CA certificate file to 'root'.Impact-None.Default Value-By default, the ownership and group-ownership for TLS CA certificate file is correctly set to
'root'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_TLS_CA_FILE@ replaced with "/etc/docker/certs.d/CA_CERT" in field "file".
      file        : "/etc/docker/certs.d/CA_CERT"
      owner       : "root"
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.10 Verify that TLS CA certificate file permissions are set to 444 or more restrictive"
      info        : "Verify that the TLS CA certificate file (the file that is passed alongwith '--
tlscacert' parameter) has permissions of '444' or more restrictive.The TLS CA certificate file should be protected from any tampering. It is used to
authenticate Docker server based on given CA certificate. Hence, it must have permissions
of '444' to maintain the integrity of the CA certificate."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/articles/https/"
      solution    : "chmod 444 <path to TLS CA certificate file>
This would set the file permissions of the TLS CA file to '444'.Impact-None.Default Value-By default, the permissions for TLS CA certificate file might not be '444'. The default file
permissions are governed by the system or user specific umask values."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_TLS_CA_FILE@ replaced with "/etc/docker/certs.d/CA_CERT" in field "file".
      file        : "/etc/docker/certs.d/CA_CERT"
      mask        : "333"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.11 Verify that Docker server certificate file ownership is set to root:root"
      info        : "Verify that the Docker server certificate file (the file that is passed alongwith '--
tlscert' parameter) is owned and group-owned by 'root'.The Docker server certificate file should be protected from any tampering. It is used to
authenticate Docker server based on the given server certificate. Hence, it must be owned
and group-owned by 'root' to maintain the integrity of the certificate."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/articles/https/"
      solution    : "chown root-root <path to Docker server certificate file>
This would set the ownership and group-ownership for the Docker server certificate file to
'root'.Impact-None.Default Value-By default, the ownership and group-ownership for Docker server certificate file is
correctly set to 'root'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_SERVER_CERT_FILE@ replaced with "/etc/docker/certs.d/DOCKER_SERVER_CERT" in field "file".
      file        : "/etc/docker/certs.d/DOCKER_SERVER_CERT"
      owner       : "root"
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.12 Verify that Docker server certificate file permissions are set to 444 or more restrictive"
      info        : "Verify that the Docker server certificate file (the file that is passed alongwith '--
tlscert' parameter) has permissions of '444' or more restrictive.The Docker server certificate file should be protected from any tampering. It is used to
authenticate Docker server based on the given server certificate. Hence, it must have
permissions of '444' to maintain the integrity of the certificate."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/articles/https/"
      solution    : "chmod 444 <path to Docker server certificate file>
This would set the file permissions of the Docker server file to '444'.Impact-None.Default Value-By default, the permissions for Docker server certificate file might not be '444'. The default
file permissions are governed by the system or user specific umask values."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_SERVER_CERT_FILE@ replaced with "/etc/docker/certs.d/DOCKER_SERVER_CERT" in field "file".
      file        : "/etc/docker/certs.d/DOCKER_SERVER_CERT"
      mask        : "333"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.13 Verify that Docker server certificate key file ownership is set to root:root"
      info        : "Verify that the Docker server certificate key file (the file that is passed alongwith '--
tlskey' parameter) is owned and group-owned by 'root'.The Docker server certificate key file should be protected from any tampering or unneeded
reads. It holds the private key for the Docker server certificate. Hence, it must be owned
and group-owned by 'root' to maintain the integrity of the Docker server certificate."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/articles/https/"
      solution    : "chown root-root <path to Docker server certificate key file>
This would set the ownership and group-ownership for the Docker server certificate key
file to 'root'.Impact-None.Default Value-By default, the ownership and group-ownership for Docker server certificate key file is
correctly set to 'root'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_SERVER_CERT_KEY_FILE@ replaced with "/etc/docker/certs.d/DOCKER_SERVER_CERT_KEY" in field "file".
      file        : "/etc/docker/certs.d/DOCKER_SERVER_CERT_KEY"
      owner       : "root"
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.14 Verify that Docker server certificate key file permissions are set to 400"
      info        : "Verify that the Docker server certificate key file (the file that is passed alongwith '--
tlskey' parameter) has permissions of '400'.The Docker server certificate key file should be protected from any tampering or unneeded
reads. It holds the private key for the Docker server certificate. Hence, it must have
permissions of '400' to maintain the integrity of the Docker server certificate."
      info        : "https://docs.docker.com/articles/certificates/
2.http://docs.docker.com/articles/https/"
      solution    : "chmod 400 <path to Docker server certificate key file>
This would set the Docker server certificate key file permissions to '400'.Impact-None.Default Value-By default, the permissions for Docker server certificate key file might not be '400'. The
default file permissions are governed by the system or user specific umask values."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
# Note: Variable @PATH_TO_SERVER_CERT_KEY_FILE@ replaced with "/etc/docker/certs.d/DOCKER_SERVER_CERT_KEY" in field "file".
      file        : "/etc/docker/certs.d/DOCKER_SERVER_CERT_KEY"
      mask        : "377"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.15 Verify that Docker socket file ownership is set to root:docker"
      info        : "Verify that the Docker socket file is owned by 'root' and group-owned by 'docker'.Docker daemon runs as 'root'. The default Unix socket hence must be owned by 'root'. If
any other user or process owns this socket, then it might be possible for that non-
privileged user or process to interact with Docker daemon. Also, such a non-privileged user
or process might interact with containers. This is neither secure nor desired behavior.Additionally, the Docker installer creates a Unix group called 'docker'. You can add users to
this group, and then those users would be able to read and write to default Docker Unix
socket. The membership to the 'docker' group is tightly controlled by the system
administrator. If any other group owns this socket, then it might be possible for members
of that group to interact with Docker daemon. Also, such a group might not be as tightly
controlled as the 'docker' group. This is neither secure nor desired behavior.Hence, the default Docker Unix socket file must be owned by 'root' and group-owned by
'docker' to maintain the integrity of the socket file."
      info        : "https://docs.docker.com/reference/commandline/cli/#daemon-socket-option
2.https://docs.docker.com/articles/basics/#bind-docker-to-another-hostport-or-a-unix-socket"
      solution    : "chown root-docker /var/run/docker.sock
This would set the ownership to 'root' and group-ownership to 'docker' for default Docker
socket file.
Impact-None.Default Value-By default, the ownership and group-ownership for Docker socket file is correctly set to
'root-docker'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/var/run/docker.sock"
      owner       : "root"
      group       : "docker"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.16 Verify that Docker socket file permissions are set to 660 or more restrictive"
      info        : "Verify that the Docker socket file has permissions of '660' or more restrictive.Only 'root' and members of 'docker' group should be allowed to read and write to default
Docker Unix socket. Hence, the Docket socket file must have permissions of '660' or more
restrictive."
      info        : "https://docs.docker.com/reference/commandline/cli/#daemon-socket-option
2.https://docs.docker.com/articles/basics/#bind-docker-to-another-hostport-or-a-unix-socket"
      solution    : "chmod 660 /var/run/docker.sock
This would set the file permissions of the Docker socket file to '660'.Impact-None.Default Value-By default, the permissions for Docker socket file is correctly set to '660'."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/var/run/docker.sock"
      mask        : "117"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.17 Verify that daemon.json file ownership is set to root:root"
      info        : "Verify that the 'daemon.json' file ownership and group-ownership is correctly set to 'root'.'daemon.json' file contains sensitive parameters that may alter the behavior of docker
daemon. Hence, it should be owned and group-owned by 'root' to maintain the integrity of
the file."
      info        : "https://docs.docker.com/engine/reference/commandline/daemon/#daemon-configuration-file"
      solution    : "chown root-root /etc/docker/daemon.json
This would set the ownership and group-ownership for the file to 'root'.Impact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/etc/docker/daemon.json"
      owner       : "root"
      required    : NO
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.18 Verify that daemon.json file permissions are set to 644 or more restrictive"
      info        : "Verify that the 'daemon.json' file permissions are correctly set to '644' or more restrictive.'daemon.json' file contains sensitive parameters that may alter the behavior of docker
daemon. Hence, it should be writable only by 'root' to maintain the integrity of the file."
      info        : "https://docs.docker.com/engine/reference/commandline/daemon/#daemon-configuration-file"
      solution    : "chmod 644 /etc/docker/daemon.json
This would set the file permissions for this file to '644'.Impact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/etc/docker/daemon.json"
      mask        : "133"
      required    : NO
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.19 Verify that /etc/default/docker file ownership is set to root:root"
      info        : "Verify that the '/etc/default/docker' file ownership and group-ownership is correctly set
to 'root'.'/etc/default/docker' file contains sensitive parameters that may alter the behavior of
docker daemon. Hence, it should be owned and group-owned by 'root' to maintain the
integrity of the file."
      info        : "https://docs.docker.com/engine/admin/configuring/"
      solution    : "chown root-root /etc/default/docker
This would set the ownership and group-ownership for the file to 'root'.Impact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/etc/default/docker"
      owner       : "root"
      required    : NO
      group       : "root"
    </custom_item>

    <custom_item>
      type        : FILE_CHECK
      description : "3.20 Verify that /etc/default/docker file permissions are set to 644 or more restrictive"
      info        : "Verify that the '/etc/default/docker' file permissions are correctly set to '644' or more
restrictive.'/etc/default/docker' file contains sensitive parameters that may alter the behavior of
docker daemon. Hence, it should be writable only by 'root' to maintain the integrity of the
file."
      info        : "https://docs.docker.com/engine/admin/configuring/"
      solution    : "chmod 644 /etc/default/docker
This would set the file permissions for this file to '644'.Impact-None.Default Value-This file may not be present on the system. In that case, this recommendation is not
applicable."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSCv6|3.1,CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,PCI-DSSv3.1|2.2.4,PCI-DSSv3.2|2.2.4,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      file        : "/etc/default/docker"
      mask        : "133"
      required    : NO
    </custom_item>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "4.1 Create a user for the container"
          cmd         : "/usr/bin/docker ps -q | xargs docker inspect --format '{{ .Id }}: User={{.Config.User}}'"
          expect      : "User=$"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "4.1 Create a user for the container"
          info        : "Create a non-root user for the container in the Dockerfile for the container image.It is a good practice to run the container as a non-root user, if possible. Though user
namespace mapping is now available, if a user is already defined in the container image, the
container is run as that user by default and specific user namespace remapping is not
required."
          info        : "https://github.com/docker/docker/issues/2918
2.https://github.com/docker/docker/pull/4572
3.https://github.com/docker/docker/issues/7906
4.https://www.altiscale.com/hadoop-blog/making-docker-work-yarn/
5.http://docs.docker.com/articles/security/"
          solution    : "Ensure that the Dockerfile for the container image contains below instruction-USER <username or ID>where username or ID refers to the user that could be found in the container base image. If
there is no specific user created in the container base image, then add a useradd command
to add the specific user before USER instruction.For example, add the below lines in the Dockerfile to create a user in the container-RUN useradd -d /home/username -m -s /bin/bash username
USER usernameNote- If there are users in the image that the containers do not need, consider deleting
them. After deleting those users, commit the image and then generate new instances of
containers for use.Impact-None.Default Value-By default, the containers are run with root privileges and as user root inside the
container."
          reference   : "800-171|3.1.5,800-53|AC-6,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.10.6(a),CN-L3|8.1.4.2(d),CSF|PR.AC-4,CSF|PR.DS-5,ITSG-33|AC-6,LEVEL|1S,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs docker inspect --format '{{ .Id }}: User={{.Config.User}}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "4.1 Create a user for the container"
          info        : "Create a non-root user for the container in the Dockerfile for the container image.It is a good practice to run the container as a non-root user, if possible. Though user
namespace mapping is now available, if a user is already defined in the container image, the
container is run as that user by default and specific user namespace remapping is not
required."
          info        : "https://github.com/docker/docker/issues/2918
2.https://github.com/docker/docker/pull/4572
3.https://github.com/docker/docker/issues/7906
4.https://www.altiscale.com/hadoop-blog/making-docker-work-yarn/
5.http://docs.docker.com/articles/security/"
          solution    : "Ensure that the Dockerfile for the container image contains below instruction-USER <username or ID>where username or ID refers to the user that could be found in the container base image. If
there is no specific user created in the container base image, then add a useradd command
to add the specific user before USER instruction.For example, add the below lines in the Dockerfile to create a user in the container-RUN useradd -d /home/username -m -s /bin/bash username
USER usernameNote- If there are users in the image that the containers do not need, consider deleting
them. After deleting those users, commit the image and then generate new instances of
containers for use.Impact-None.Default Value-By default, the containers are run with root privileges and as user root inside the
container."
          reference   : "800-171|3.1.5,800-53|AC-6,CN-L3|7.1.3.2(b),CN-L3|7.1.3.2(g),CN-L3|8.1.10.6(a),CN-L3|8.1.4.2(d),CSF|PR.AC-4,CSF|PR.DS-5,ITSG-33|AC-6,LEVEL|1S,NESA|T5.1.1,NESA|T5.2.2,NESA|T5.4.1,NESA|T5.4.4,NESA|T5.4.5,NESA|T5.5.4,NESA|T5.6.1,NESA|T7.5.3,NIAv2|AM1,NIAv2|AM23f,NIAv2|SS13c,NIAv2|SS15c,SWIFT-CSCv1|5.1,TBA-FIISB|31.4.2,TBA-FIISB|31.4.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs docker inspect --format '{{ .Id }}: User={{.Config.User}}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <custom_item>
      type        : CMD_EXEC
      description : "4.2 Use trusted base images for containers"
      info        : "Ensure that the container image is written either from scratch or is based on another
established and trusted base image downloaded over a secure channel.Official repositories are Docker images curated and optimized by the Docker community or
the vendor. There could be other potentially unsafe public repositories. You should thus
exercise a lot of caution when obtaining container images."
      info        : "https://titanous.com/posts/docker-insecurity
2.https://registry.hub.docker.com/
3.http://blog.docker.com/2014/10/docker-1-3-signed-images-process-injection-security-options-mac-shared-directories/
4.https://github.com/docker/docker/issues/8093
5.http://docs.docker.com/reference/commandline/cli/#pull
6.https://github.com/docker/docker/pull/11109
7.https://blog.docker.com/2015/11/docker-trusted-registry-1-4/
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Configure and use Docker Content trust.Impact-None.Default Value-Not Applicable."
      reference   : "800-171|3.4.8,800-53|CM-7(5),CSF|PR.IP-1,CSF|PR.PT-3,ISO/IEC-27001|A.12.5.1,ISO/IEC-27001|A.12.6.2,LEVEL|1NS,SWIFT-CSCv1|2.3,TBA-FIISB|44.2.2,TBA-FIISB|49.2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker images"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <item>
      description : "4.3 Do not install unnecessary packages in the container"
      info        : "Containers tend to be minimal and slim down versions of the Operating System. Do not
install anything that does not justify the purpose of container.Bloating containers with unnecessary software could possibly increase the attack surface
of the container. This also voids the concept of minimal and slim down versions of
container images. Hence, do not install anything else apart from what is truly needed for
the purpose of the container."
      info        : "https://docs.docker.com/userguide/dockerimages/
2.http://www.livewyer.com/blog/2015/02/24/slimming-down-your-docker-containers-alpine-linux
3.https://github.com/progrium/busybox"
      solution    : "At the outset, do not install anything on the container that does not justify the purpose. If
the image had some packages that your container does not use, uninstall them.Consider using a minimal base image rather than the standard Redhat/Centos/Debian
images if you can. Some of the options include BusyBox and Alpine.Not only does this trim your image size from >150Mb to ~20 Mb, there are also fewer tools
and paths to escalate privileges. You can even remove the package installer as a final
hardening measure for leaf/production containers.Impact-None.
Default Value-Not Applicable."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1NS,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      name        : "list_docker_container_packages"
    </item>

    <item>
      description : "4.4 Rebuild the images to include security patches"
      info        : "Images should be scanned 'frequently' for any vulnerabilities. Rebuild the images to
include patches and then instantiate new containers from it.Vulnerabilities are loopholes/bugs that can be exploited and security patches are updates
to resolve these vulnerabilities. We can use image vulnerability scanning tools to find any
kind of vulnerabilities within the images and then check for available patches to mitigate
these vulnerabilities. Patches update the system to the most recent code base. Being on the
current code base is important because that's where vendors focus on fixing problems.
Evaluate the security patches before applying and follow the patching best practices.Also, it would be better if, image vulnerability scanning tools could perform binary level
analysis or hash based verification instead of just version string matching."
      info        : "https://docs.docker.com/userguide/dockerimages/"
      solution    : "Follow the below steps to rebuild the images with security patches-
Step 1- 'docker pull' all the base images (i.e., given your set of Dockerfiles, extract all
images declared in 'FROM' instructions, and re-pull them to check for an updated/patched
versions). Patch the packages within the images too.
Step 2- Force a rebuild of each image with 'docker build --no-cache'.
Step 3- Restart all containers with the updated images.You could also use ONBUILD directive in the Dockerfile to trigger particular update
instructions for images that you know are used as base images frequently.Impact-NoneDefault Value-By default, containers and images are not updated of their own."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1NS,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      name        : "list_docker_container_packages"
    </item>

    <custom_item>
      type        : CMD_EXEC
      description : "4.6 Add HEALTHCHECK instruction to the container image"
      info        : "Add HEALTHCHECK instruction in your docker container images to perform the health check
on running containers.One of the important security triads is availability. Adding HEALTHCHECK instruction to your
container image ensures that the docker engine periodically checks the running container
instances against that instruction to ensure that the instances are still working.Based on the reported health status, the docker engine could then exit non-working
containers and instantiate new ones."
      info        : "https://github.com/docker/docker/pull/22719"
      solution    : "Follow Docker documentation and rebuild your container image with HEALTHCHECK
instruction.Impact-None.Default Value-By default, HEALTHCHECK is not set.
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{.Config.Healthcheck}}'"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "4.7 Do not use update instructions alone in the Dockerfile"
      info        : "Do not use update instructions such as apt-get update alone or in a single line in the
Dockerfile.Adding the update instructions in a single line on the Dockerfile will cache the update layer.
Thus, when you build any image later using the same instruction, previously cached update
layer will be used. This could potentially deny any fresh updates to go in the later builds."
      info        : "https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-
practices/#/apt-get
2.https://github.com/docker/docker/issues/3313
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Use update instructions along with install instructions (or any other) and version pinning
for packages while installing them. This would bust the cache and force to extract the
required versions.Alternatively, you could use --no-cache flag during docker build process to avoid using
cached layers.Impact-None
Default Value-By default, docker does not enforce any restrictions on using update instructions."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1NS,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "for image in $(docker images|awk {'print $3'}); do docker history $image 2>/dev/null|grep -i UPDATE;done"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "4.9 Use COPY instead of ADD in Dockerfile"
      info        : "Use COPY instruction instead of ADD instruction in the Dockerfile.COPY instruction just copies the files from the local host machine to the container file
system. ADD instruction potentially could retrieve files from remote URLs and perform
operations such as unpacking. Thus, ADD instruction introduces risks such as adding
malicious files from URLs without scanning and unpacking procedure vulnerabilities."
      info        : "https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-
practices/#/add-or-copy"
      solution    : "Use COPY instructions in Dockerfiles.Impact-You would need to take care of the functionalities provided by ADD instructions such as
fetching files from remote URLs.Default Value-Not Applicable"
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1NS,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "for image in $(docker images|awk {'print $3'}); do docker history $image 2>/dev/null|grep ADD;done"
      expect      : ""
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "4.10 Do not store secrets in Dockerfiles"
      info        : "Do not store any secrets in Dockerfiles.Dockerfiles could be backtracked easily by using native Docker commands such as docker
history and various tools and utilities. Also, as a general practice, image publishers
provide Dockerfiles to build the credibility for their images. Hence, the secrets within these
Dockerfiles could be easily exposed and potentially be exploited."
      info        : "https://github.com/docker/docker/issues/13490
2.http://12factor.net/config
3.https://avicoder.me/2016/07/22/Twitter-Vine-Source-code-dump/
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Do not store any kind of secrets within Dockerfiles.Impact-You would need to identify a way to handle secrets for your Docker images.Default Value-By default, there are no restrictions on storing config secrets in the Dockerfiles."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1NS,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "for image in $(docker images|awk {'print $3'}); do docker history $image;done"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "5.3 Restrict Linux Kernel Capabilities within containers"
      info        : "By default, Docker starts containers with a restricted set of Linux Kernel Capabilities. It
means that any process may be granted the required capabilities instead of root access.
Using Linux Kernel Capabilities, the processes do not have to run as root for almost all the
specific areas where root privileges are usually needed.Docker supports the addition and removal of capabilities, allowing use of a non-default
profile. This may make Docker more secure through capability removal, or less secure
through the addition of capabilities. It is thus recommended to remove all capabilities
except those explicitly required for your container process.For example, capabilities such as below are usually not needed for container process:NET_ADMIN
SYS_ADMIN
SYS_MODULE"
      info        : "https://docs.docker.com/articles/security/#linux-kernel-capabilities
2.https://github.com/docker/docker/blob/master/daemon/execdriver/native/template/default_template.go
3.http://man7.org/linux/man-pages/man7/capabilities.7.html
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Execute the below command to add needed capabilities-$> docker run --cap-add={'Capability 1','Capability 2'} <Run arguments> <Container
Image Name or ID> <Command>For example,docker run --interactive --tty --cap-add={'NET_ADMIN','SYS_ADMIN'} centos-latest
/bin/bashExecute the below command to drop unneeded capabilities-$> docker run --cap-drop={'Capability 1','Capability 2'} <Run arguments> <Container
Image Name or ID> <Command>For example,docker run --interactive --tty --cap-drop={'SETUID','SETGID'} centos-latest /bin/bashAlternatively,You may choose to drop all capabilities and add only add the needed ones-$> docker run --cap-drop=all --cap-add={'Capability 1','Capability 2'} <Run arguments>
<Container Image Name or ID> <Command>For example,docker run --interactive --tty --cap-drop=all --cap-add={'NET_ADMIN','SYS_ADMIN'}
centos-latest /bin/bashImpact-Based on what Linux Kernel Capabilities were added or dropped, restrictions within the
container would apply.Default Value-By default, below capabilities are available for containers-AUDIT_WRITE
CHOWN
DAC_OVERRIDE
FOWNER
FSETID
KILL
MKNOD
NET_BIND_SERVICE
NET_RAW
SETFCAP
SETGID
SETPCAP
SETUID
SYS_CHROOT"
      reference   : "800-53|AC-6(4),CSF|PR.AC-4,ITSG-33|AC-6(4),LEVEL|1S"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: CapAdd={{json .HostConfig.CapAdd }} CapDrop={{json .HostConfig.CapDrop }}'"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.4 Do not use privileged containers"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Privileged={{ .HostConfig.Privileged }}'"
          expect      : "Privileged=true"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.4 Do not use privileged containers"
          info        : "Using the --privileged flag gives all Linux Kernel Capabilities to the container thus
overwriting the --cap-add and --cap-drop flags. Ensure that it is not used.The --privileged flag gives all capabilities to the container, and it also lifts all the
limitations enforced by the device cgroup controller. In other words, the container can then
do almost everything that the host can do. This flag exists to allow special use-cases, like
running Docker within Docker."
          info        : "https://docs.docker.com/reference/commandline/cli"
          solution    : "Do not run container with the --privileged flag.For example, do not start a container as below-docker run --interactive --tty --privileged centos /bin/bashImpact-Linux Kernel Capabilities other than defaults would not be available for use within
container.Default Value-False."
          reference   : "800-53|AC-6(4),CSF|PR.AC-4,ITSG-33|AC-6(4),LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Privileged={{ .HostConfig.Privileged }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.4 Do not use privileged containers"
          info        : "Using the --privileged flag gives all Linux Kernel Capabilities to the container thus
overwriting the --cap-add and --cap-drop flags. Ensure that it is not used.The --privileged flag gives all capabilities to the container, and it also lifts all the
limitations enforced by the device cgroup controller. In other words, the container can then
do almost everything that the host can do. This flag exists to allow special use-cases, like
running Docker within Docker."
          info        : "https://docs.docker.com/reference/commandline/cli"
          solution    : "Do not run container with the --privileged flag.For example, do not start a container as below-docker run --interactive --tty --privileged centos /bin/bashImpact-Linux Kernel Capabilities other than defaults would not be available for use within
container.Default Value-False."
          reference   : "800-53|AC-6(4),CSF|PR.AC-4,ITSG-33|AC-6(4),LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Privileged={{ .HostConfig.Privileged }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <custom_item>
      type        : CMD_EXEC
      description : "5.5 Do not mount sensitive host system directories on containers"
      info        : "Sensitive host system directories such as below should not be allowed to be mounted as
container volumes especially in read-write mode./
/boot
/dev
/etc
/lib
/proc
/sys
/usrIf sensitive directories are mounted in read-write mode, it would be possible to make
changes to files within those sensitive directories. The changes might bring down security
implications or unwarranted changes that could put the Docker host in compromised state."
      info        : "https://docs.docker.com/userguide/dockervolumes"
      solution    : "Do not mount host sensitive directories on containers especially in read-write mode.Impact-None.Default Value-Docker defaults to a read-write volume but you can also mount a directory read-only. By
default, no sensitive host directories are mounted on containers.
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker ps -q | xargs docker inspect --format '{{ .Id }}: Volumes={{ .Mounts }}'"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "5.6 Do not run ssh within containers"
      info        : "SSH server should not be running within the container. You should SSH into the Docker
host, and use nsenter tool to enter a container from a remote host.Running SSH within the container increases the complexity of security management by
making it. Difficult to manage access policies and security compliance for SSH server
. Difficult to manage keys and passwords across various containers
. Difficult to manage security upgrades for SSH serverIt is possible to have shell access to a container without using SSH, the needlessly
increasing the complexity of security management should be avoided."
      info        : "http://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/"
      solution    : "Uninstall SSH server from the container and use nsenter or any other commands such as
docker exec or docker attach to interact with the container instance.docker exec --interactive --tty $INSTANCE_ID shORdocker attach $INSTANCE_IDImpact-None.
Default Value-By default, SSH server is not running inside the container. Only one process per container is
allowed."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "for i in $(/usr/bin/docker ps -q); do /usr/bin/docker exec $i ps -el|grep ssh; done"
      expect      : ""
    </custom_item>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.7 Do not map privileged ports within containers"
          cmd         : "for i in $(/usr/bin/docker ps -q); do echo $i ' : ';/usr/bin/docker port $i; done"
          expect      : ":([0-9]|[1-9][0-9]|[1-9][0-9][0-9]|10[0-2][0-3])$"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.7 Do not map privileged ports within containers"
          info        : "The TCP/IP port numbers below 1024 are considered privileged ports. Normal users and
processes are not allowed to use them for various security reasons. Docker allows a
container port to be mapped to a privileged port.By default, if the user does not specifically declare the container port to host port mapping,
Docker automatically and correctly maps the container port to one available in 49153-
65535 block on the host. But, Docker allows a container port to be mapped to a privileged
port on the host if the user explicitly declared it. This is so because containers are executed
with NET_BIND_SERVICE Linux kernel capability that does not restrict the privileged port
mapping. The privileged ports receive and transmit various sensitive and privileged data.
Allowing containers to use them can bring serious implications."
          info        : "http://docs.docker.com/articles/networking/#binding-ports
2.https://www.adayinthelifeof.nl/2012/03/12/why-putting-ssh-on-another-port-than-22-is-bad-idea"
          solution    : "Do not map the container ports to privileged host ports when starting a container. Also,
ensure that there is no such container to host privileged port mapping declarations in the
Dockerfile.Impact-None.Default Value-By default, mapping a container port to a privileged port on the host is allowed.Note- There might be certain cases where you want to map privileged ports, because if you
forbid it, then the corresponding application has to run outside of a container.For example- HTTP and HTTPS load balancers have to bind 80/tcp and 443/tcp
respectively. Forbidding to map privileged ports effectively forbids from running those in a
container, and mandates using an external load balancer. In such cases, those containers
instances should be marked as exceptions for this recommendation."
          reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "for i in $(/usr/bin/docker ps -q); do echo $i ' : ';/usr/bin/docker port $i; done"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.7 Do not map privileged ports within containers"
          info        : "The TCP/IP port numbers below 1024 are considered privileged ports. Normal users and
processes are not allowed to use them for various security reasons. Docker allows a
container port to be mapped to a privileged port.By default, if the user does not specifically declare the container port to host port mapping,
Docker automatically and correctly maps the container port to one available in 49153-
65535 block on the host. But, Docker allows a container port to be mapped to a privileged
port on the host if the user explicitly declared it. This is so because containers are executed
with NET_BIND_SERVICE Linux kernel capability that does not restrict the privileged port
mapping. The privileged ports receive and transmit various sensitive and privileged data.
Allowing containers to use them can bring serious implications."
          info        : "http://docs.docker.com/articles/networking/#binding-ports
2.https://www.adayinthelifeof.nl/2012/03/12/why-putting-ssh-on-another-port-than-22-is-bad-idea"
          solution    : "Do not map the container ports to privileged host ports when starting a container. Also,
ensure that there is no such container to host privileged port mapping declarations in the
Dockerfile.Impact-None.Default Value-By default, mapping a container port to a privileged port on the host is allowed.Note- There might be certain cases where you want to map privileged ports, because if you
forbid it, then the corresponding application has to run outside of a container.For example- HTTP and HTTPS load balancers have to bind 80/tcp and 443/tcp
respectively. Forbidding to map privileged ports effectively forbids from running those in a
container, and mandates using an external load balancer. In such cases, those containers
instances should be marked as exceptions for this recommendation."
          reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "for i in $(/usr/bin/docker ps -q); do echo $i ' : ';/usr/bin/docker port $i; done"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <custom_item>
      type        : CMD_EXEC
      description : "5.8 Open only needed ports on container"
      info        : "Dockerfile for a container image defines the ports to be opened by default on a container
instance. The list of ports may or may not be relevant to the application you are running
within the container.A container can be run just with the ports defined in the Dockerfile for its image or can be
arbitrarily passed run time parameters to open a list of ports. Additionally, Overtime,
Dockerfile may undergo various changes and the list of exposed ports may or may not be
relevant to the application you are running within the container. Opening unneeded ports
increase the attack surface of the container and the containerized application. As a
recommended practice, do not open unneeded ports."
      info        : "https://docs.docker.com/articles/networking/#binding-ports
  NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Fix the Dockerfile of the container image to expose only needed ports by your
containerized application. You can also completely ignore the list of ports defined in the
Dockerfile by NOT using '-P' (UPPERCASE) or '--publish-all' flag when starting the
container. Use the '-p' (lowercase) or '--publish' flag to explicitly define the ports that
you need for a particular container instance.For example,docker run --interactive --tty --publish 5000 --publish 5001 --publish 5002 centos
/bin/bash
Impact-None.Default Value-By default, all the ports that are listed in the Dockerfile under EXPOSE instruction for an
image are opened when container is run with '-P' or '--publish-all' flag."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "for i in $(/usr/bin/docker ps -q); do /usr/bin/docker port $i; done"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.9 Do not share the host's network namespace"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: NetworkMode={{ .HostConfig.NetworkMode }}'"
          expect      : "host"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.9 Do not share the host's network namespace"
          info        : "The networking mode on a container when set to '--net=host', skips placing the container
inside separate network stack. In essence, this choice tells Docker to not containerize the
container's networking. This would network-wise mean that the container lives 'outside'
in the main Docker host and has full access to its network interfaces.This is potentially dangerous. It allows the container process to open low-numbered ports
like any other root process. It also allows the container to access network services like D-
bus on the Docker host. Thus, a container process can potentially do unexpected things
such as shutting down the Docker host. You should not use this option."
          info        : "http://docs.docker.com/articles/networking/#how-docker-networks-a-container
2.https://github.com/docker/docker/issues/6401"
          solution    : "Do not pass '--net=host' option when starting the container.Impact-None.Default Value-By default, container connects to Docker bridge."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: NetworkMode={{ .HostConfig.NetworkMode }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.9 Do not share the host's network namespace"
          info        : "The networking mode on a container when set to '--net=host', skips placing the container
inside separate network stack. In essence, this choice tells Docker to not containerize the
container's networking. This would network-wise mean that the container lives 'outside'
in the main Docker host and has full access to its network interfaces.This is potentially dangerous. It allows the container process to open low-numbered ports
like any other root process. It also allows the container to access network services like D-
bus on the Docker host. Thus, a container process can potentially do unexpected things
such as shutting down the Docker host. You should not use this option."
          info        : "http://docs.docker.com/articles/networking/#how-docker-networks-a-container
2.https://github.com/docker/docker/issues/6401"
          solution    : "Do not pass '--net=host' option when starting the container.Impact-None.Default Value-By default, container connects to Docker bridge."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: NetworkMode={{ .HostConfig.NetworkMode }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.10 Limit memory usage for container"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Memory={{ .HostConfig.Memory }}'"
          expect      : "Memory=0"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.10 Limit memory usage for container"
          info        : "By default, all containers on a Docker host share the resources equally. By using the
resource management capabilities of Docker host, such as memory limit, you can control
the amount of memory that a container may consume.By default, container can use all of the memory on the host. You can use memory limit
mechanism to prevent a denial of service arising from one container consuming all of the
hosts resources such that other containers on the same host cannot perform their intended
functions. Having no limit on memory can lead to issues where one container can easily
make the whole system unstable and as a result unusable."
          info        : "https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/
2.http://docs.docker.com/reference/commandline/cli/#run
3.https://docs.docker.com/articles/runmetrics/"
          solution    : "Run the container with only as much memory as required. Always run the container using
'-m' or '--memory' argument. You should start the container as below-$> docker run <Run arguments> --memory <memory-size> <Container Image Name or ID>
<Command>For example,docker run --interactive --tty --memory 256m centos /bin/bashIn the above example, the container is started with a memory limit of 256 MB.Note- Please note that the output of the below command would return values in scientific
notation if memory limits are in place.docker inspect --format='{{.Config.Memory}}' 7c5a2d4c7fe0
For example, if the memory limit is set to 256 MB for the above container instance, the
output of the above command would be 2.68435456e+08 and NOT 256m. You should
convert this value using a scientific calculator or programmatic methods.Impact-If you do not set proper limits, the container process may have to starve.Default Value-By default, all containers on a Docker host share the resources equally. No memory limits
are enforced."
          reference   : "800-53|SC-6,CN-L3|7.1.3.7(c),CN-L3|7.1.3.7(d),ITSG-33|SC-6,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Memory={{ .HostConfig.Memory }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.10 Limit memory usage for container"
          info        : "By default, all containers on a Docker host share the resources equally. By using the
resource management capabilities of Docker host, such as memory limit, you can control
the amount of memory that a container may consume.By default, container can use all of the memory on the host. You can use memory limit
mechanism to prevent a denial of service arising from one container consuming all of the
hosts resources such that other containers on the same host cannot perform their intended
functions. Having no limit on memory can lead to issues where one container can easily
make the whole system unstable and as a result unusable."
          info        : "https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/
2.http://docs.docker.com/reference/commandline/cli/#run
3.https://docs.docker.com/articles/runmetrics/"
          solution    : "Run the container with only as much memory as required. Always run the container using
'-m' or '--memory' argument. You should start the container as below-$> docker run <Run arguments> --memory <memory-size> <Container Image Name or ID>
<Command>For example,docker run --interactive --tty --memory 256m centos /bin/bashIn the above example, the container is started with a memory limit of 256 MB.Note- Please note that the output of the below command would return values in scientific
notation if memory limits are in place.docker inspect --format='{{.Config.Memory}}' 7c5a2d4c7fe0
For example, if the memory limit is set to 256 MB for the above container instance, the
output of the above command would be 2.68435456e+08 and NOT 256m. You should
convert this value using a scientific calculator or programmatic methods.Impact-If you do not set proper limits, the container process may have to starve.Default Value-By default, all containers on a Docker host share the resources equally. No memory limits
are enforced."
          reference   : "800-53|SC-6,CN-L3|7.1.3.7(c),CN-L3|7.1.3.7(d),ITSG-33|SC-6,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Memory={{ .HostConfig.Memory }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <custom_item>
      type        : CMD_EXEC
      description : "5.11 Set container CPU priority appropriately"
      info        : "By default, all containers on a Docker host share the resources equally. By using the
resource management capabilities of Docker host, such as CPU shares, you can control the
host CPU resources that a container may consume.By default, CPU time is divided between containers equally. If it is desired, to control the
CPU time amongst the container instances, you can use CPU sharing feature. CPU sharing
allows to prioritize one container over the other and forbids the lower priority container to
claim CPU resources more often. This ensures that the high priority containers are served
better."
      info        : "https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/
2.http://docs.docker.com/reference/commandline/cli/#run
3.https://docs.docker.com/articles/runmetrics/
NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Manage the CPU shares between your containers. To do so start the container using '-c' or
'--cpu-shares' argument. You may start the container as below-$> docker run <Run arguments> --cpu-shares <CPU shares> <Container Image Name or
ID> <Command>For example,docker run --interactive --tty --cpu-shares 512 centos /bin/bashIn the above example, the container is started with a CPU shares of 50% of what the other
containers use. So, if the other container has CPU shares of 80%, this container will have
CPU shares of 40%.
Note- Every new container will have 1024 shares of CPU by default. However, this value is
shown as '0' if you run the command mentioned in the audit section.Alternatively,1. Navigate to /sys/fs/cgroup/cpu/system.slice/ directory.
2. Check your container instance ID using 'docker ps' command.
3. Now, inside the above directory (in step 1), you would have a directory by name
'docker-<Instance ID>.scope' for example 'docker-
4acae729e8659c6be696ee35b2237cc1fe4edd2672e9186434c5116e1a6fbed6.scope'.
Navigate to this directory.
4. You will find a file named 'cpu.shares'. Execute 'cat cpu.shares'. This will always
give you the CPU share value based on the system. So, even if there are no CPU
shares configured using '-c' or '--cpu-shares' argument in the 'docker run'
command, this file will have a value of '1024'.If we set one containers CPU shares to 512 it will receive half of the CPU time compared to
the other container. So, take 1024 as 100% and then do quick math to derive the number
that you should set for respective CPU shares. For example, use 512 if you want to set 50%
and 256 if you want to set 25%.Impact-If you do not set proper CPU shares, the container process may have to starve if the
resources on the host are not available. If the CPU resources on the host are free, CPU
shares do not place any restrictions on the CPU that the container may use.Default Value-By default, all containers on a Docker host share the resources equally. No CPU shares are
enforced."
      reference   : "800-53|SC-6,CN-L3|7.1.3.7(c),CN-L3|7.1.3.7(d),ITSG-33|SC-6,LEVEL|1S"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: CpuShares={{ .HostConfig.CpuShares }}'"
      expect      : ""
      severity    : MEDIUM
    </custom_item>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.12 Mount container's root filesystem as read only"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: ReadonlyRootfs={{ .HostConfig.ReadonlyRootfs }}'"
          expect      : "ReadonlyRootfs=false"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.12 Mount container's root filesystem as read only"
          info        : "The container's root file system should be treated as a 'golden image' and any writes to
the root filesystem should be avoided. You should explicitly define a container volume for
writing.You should not be writing data within containers. The data volume belonging to a container
should be explicitly defined and administered. This is useful in many cases where the
admin controls where they would want developers to write files and errors. Also, this has
other advantages such as below:. This leads to an immutable infrastructure
. Since the container instance cannot be written to, there is no need to audit instance
divergence
. Reduced security attack vectors since the instance cannot be tampered with or
written to
. Ability to use a purely volume based backup without backing up anything from the
instance"
          info        : "http://docs.docker.com/reference/commandline/cli/#run"
          solution    : "Add a '--read-only' flag to allow the container's root filesystem to be mounted as read
only. This can be used in combination with volumes to force a container's process to only
write to locations that will be persisted.You should run the container as below-$> docker run <Run arguments> --read-only -v <writable-volume> <Container Image Name
or ID> <Command>For example,docker run --interactive --tty --read-only --volume /centdata centos /bin/bashThis would run the container with read-only root filesystem and would use 'centdata' as
container volume for writing.Impact-The container root file system would not be writable. You should explicitly define a volume
for the container for writing.Default Value-By default, a container will have its root filesystem writable allowing processes to write
files anywhere."
          reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS15a,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: ReadonlyRootfs={{ .HostConfig.ReadonlyRootfs }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.12 Mount container's root filesystem as read only"
          info        : "The container's root file system should be treated as a 'golden image' and any writes to
the root filesystem should be avoided. You should explicitly define a container volume for
writing.You should not be writing data within containers. The data volume belonging to a container
should be explicitly defined and administered. This is useful in many cases where the
admin controls where they would want developers to write files and errors. Also, this has
other advantages such as below:. This leads to an immutable infrastructure
. Since the container instance cannot be written to, there is no need to audit instance
divergence
. Reduced security attack vectors since the instance cannot be tampered with or
written to
. Ability to use a purely volume based backup without backing up anything from the
instance"
          info        : "http://docs.docker.com/reference/commandline/cli/#run"
          solution    : "Add a '--read-only' flag to allow the container's root filesystem to be mounted as read
only. This can be used in combination with volumes to force a container's process to only
write to locations that will be persisted.You should run the container as below-$> docker run <Run arguments> --read-only -v <writable-volume> <Container Image Name
or ID> <Command>For example,docker run --interactive --tty --read-only --volume /centdata centos /bin/bashThis would run the container with read-only root filesystem and would use 'centdata' as
container volume for writing.Impact-The container root file system would not be writable. You should explicitly define a volume
for the container for writing.Default Value-By default, a container will have its root filesystem writable allowing processes to write
files anywhere."
          reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS15a,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: ReadonlyRootfs={{ .HostConfig.ReadonlyRootfs }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.13 Bind incoming container traffic to a specific host interface"
          cmd         : "for i in $(/usr/bin/docker ps -q); do /usr/bin/docker port $i; done"
          expect      : "0\.0\.0\.\0:"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.13 Bind incoming container traffic to a specific host interface"
          info        : "By default, Docker containers can make connections to the outside world, but the outside
world cannot connect to containers. Each outgoing connection will appear to originate
from one of the host machine's own IP addresses. Only allow container services to be
contacted through a specific external interface on the host machine.If you have multiple network interfaces on your host machine, the container can accept
connections on the exposed ports on any network interface. This might not be desired and
may not be secured. Many a times a particular interface is exposed externally and services
such as intrusion detection, intrusion prevention, firewall, load balancing, etc. are run on
those interfaces to screen incoming public traffic. Hence, you should not accept incoming
connections on any interface. You should only allow incoming connections from a
particular external interface."
          info        : "https://docs.docker.com/articles/networking/#binding-container-ports-to-the-host"
          solution    : "Bind the container port to a specific host interface on the desired host port.For example,docker run --detach --publish 10.2.3.4-49153-80 nginxIn the example above, the container port 80 is bound to the host port on 49153 and would
accept incoming connection only from 10.2.3.4 external interface.Impact-None.Default Value-By default, Docker exposes the container ports on 0.0.0.0, the wildcard IP address that
will match any possible incoming network interface on the host machine."
          reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "for i in $(/usr/bin/docker ps -q); do /usr/bin/docker port $i; done"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.13 Bind incoming container traffic to a specific host interface"
          info        : "By default, Docker containers can make connections to the outside world, but the outside
world cannot connect to containers. Each outgoing connection will appear to originate
from one of the host machine's own IP addresses. Only allow container services to be
contacted through a specific external interface on the host machine.If you have multiple network interfaces on your host machine, the container can accept
connections on the exposed ports on any network interface. This might not be desired and
may not be secured. Many a times a particular interface is exposed externally and services
such as intrusion detection, intrusion prevention, firewall, load balancing, etc. are run on
those interfaces to screen incoming public traffic. Hence, you should not accept incoming
connections on any interface. You should only allow incoming connections from a
particular external interface."
          info        : "https://docs.docker.com/articles/networking/#binding-container-ports-to-the-host"
          solution    : "Bind the container port to a specific host interface on the desired host port.For example,docker run --detach --publish 10.2.3.4-49153-80 nginxIn the example above, the container port 80 is bound to the host port on 49153 and would
accept incoming connection only from 10.2.3.4 external interface.Impact-None.Default Value-By default, Docker exposes the container ports on 0.0.0.0, the wildcard IP address that
will match any possible incoming network interface on the host machine."
          reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "for i in $(/usr/bin/docker ps -q); do /usr/bin/docker port $i; done"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.14 Set the 'on-failure' container restart policy to 5 - RestartPolicyName=always"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: RestartPolicyName={{ .HostConfig.RestartPolicy.Name }} MaximumRetryCount={{ .HostConfig.RestartPolicy.MaximumRetryCount }}'"
          expect      : "RestartPolicyName=always"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.14 Set the 'on-failure' container restart policy to 5 - RestartPolicyName=always"
          info        : "Using the '--restart' flag in 'docker run' command you can specify a restart policy for
how a container should or should not be restarted on exit. You should choose the 'on-
failure' restart policy and limit the restart attempts to 5.If you indefinitely keep trying to start the container, it could possibly lead to a denial of
service on the host. It could be an easy way to do a distributed denial of service attack
especially if you have many containers on the same host. Additionally, ignoring the exit
status of the container and 'always' attempting to restart the container leads to non-
investigation of the root cause behind containers getting terminated. If a container gets
terminated, you should investigate on the reason behind it instead of just attempting to
restart it indefinitely. Thus, it is recommended to use 'on-failure' restart policy and limit
it to maximum of 5 restart attempts."
          info        : "http://docs.docker.com/ reference/commandline/cli/#restart-policies"
          solution    : "If a container is desired to be restarted of its own, then start the container as below-$> docker run <Run arguments> --restart=on-failure-5 <Container Image Name or ID>
<Command>
For example,docker run --detach --restart=on-failure-5 nginxImpact-The container would attempt to restart only for 5 times.Default Value-By default, containers are not configured with restart policies. Hence, containers do not
attempt to restart of their own."
          reference   : "800-53|SC-5,CSF|DE.CM-1,CSF|PR.DS-4,ITSG-33|SC-5,LEVEL|1S,NESA|T3.3.1,NIAv2|GS10c,NIAv2|GS8e"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: RestartPolicyName={{ .HostConfig.RestartPolicy.Name }} MaximumRetryCount={{ .HostConfig.RestartPolicy.MaximumRetryCount }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.14 Set the 'on-failure' container restart policy to 5 - RestartPolicyName=always"
          info        : "Using the '--restart' flag in 'docker run' command you can specify a restart policy for
how a container should or should not be restarted on exit. You should choose the 'on-
failure' restart policy and limit the restart attempts to 5.If you indefinitely keep trying to start the container, it could possibly lead to a denial of
service on the host. It could be an easy way to do a distributed denial of service attack
especially if you have many containers on the same host. Additionally, ignoring the exit
status of the container and 'always' attempting to restart the container leads to non-
investigation of the root cause behind containers getting terminated. If a container gets
terminated, you should investigate on the reason behind it instead of just attempting to
restart it indefinitely. Thus, it is recommended to use 'on-failure' restart policy and limit
it to maximum of 5 restart attempts."
          info        : "http://docs.docker.com/ reference/commandline/cli/#restart-policies"
          solution    : "If a container is desired to be restarted of its own, then start the container as below-$> docker run <Run arguments> --restart=on-failure-5 <Container Image Name or ID>
<Command>
For example,docker run --detach --restart=on-failure-5 nginxImpact-The container would attempt to restart only for 5 times.Default Value-By default, containers are not configured with restart policies. Hence, containers do not
attempt to restart of their own."
          reference   : "800-53|SC-5,CSF|DE.CM-1,CSF|PR.DS-4,ITSG-33|SC-5,LEVEL|1S,NESA|T3.3.1,NIAv2|GS10c,NIAv2|GS8e"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: RestartPolicyName={{ .HostConfig.RestartPolicy.Name }} MaximumRetryCount={{ .HostConfig.RestartPolicy.MaximumRetryCount }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <custom_item>
      type        : CMD_EXEC
      description : "5.14 Set the 'on-failure' container restart policy to 5 - RestartPolicyName=on-failure"
      info        : "Using the '--restart' flag in 'docker run' command you can specify a restart policy for
how a container should or should not be restarted on exit. You should choose the 'on-
failure' restart policy and limit the restart attempts to 5.If you indefinitely keep trying to start the container, it could possibly lead to a denial of
service on the host. It could be an easy way to do a distributed denial of service attack
especially if you have many containers on the same host. Additionally, ignoring the exit
status of the container and 'always' attempting to restart the container leads to non-
investigation of the root cause behind containers getting terminated. If a container gets
terminated, you should investigate on the reason behind it instead of just attempting to
restart it indefinitely. Thus, it is recommended to use 'on-failure' restart policy and limit
it to maximum of 5 restart attempts."
      info        : "http://docs.docker.com/ reference/commandline/cli/#restart-policies"
      solution    : "If a container is desired to be restarted of its own, then start the container as below-$> docker run <Run arguments> --restart=on-failure-5 <Container Image Name or ID>
<Command>
For example,docker run --detach --restart=on-failure-5 nginxImpact-The container would attempt to restart only for 5 times.Default Value-By default, containers are not configured with restart policies. Hence, containers do not
attempt to restart of their own."
      reference   : "800-53|SC-5,CSF|DE.CM-1,CSF|PR.DS-4,ITSG-33|SC-5,LEVEL|1S,NESA|T3.3.1,NIAv2|GS10c,NIAv2|GS8e"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: RestartPolicyName={{ .HostConfig.RestartPolicy.Name }} MaximumRetryCount={{ .HostConfig.RestartPolicy.MaximumRetryCount }}'|grep RestartPolicyName=on-failure|egrep 'MaximumRetryCount=([6-9]\|[1-9][0-9]+)'"
      expect      : ""
    </custom_item>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.15 Do not share the host's process namespace"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: PidMode={{ .HostConfig.PidMode }}'"
          expect      : "PidMode=host"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.15 Do not share the host's process namespace"
          info        : "Process ID (PID) namespaces isolate the process ID number space, meaning that processes
in different PID namespaces can have the same PID. This is process level isolation between
containers and the host.PID namespace provides separation of processes. The PID Namespace removes the view of
the system processes, and allows process ids to be reused including PID 1. If the host's PID
namespace is shared with the container, it would basically allow processes within the
container to see all of the processes on the host system. This breaks the benefit of process
level isolation between the host and the containers. Someone having access to the
container can eventually know all the processes running on the host system and can even
kill the host system processes from within the container. This can be catastrophic. Hence,
do not share the host's process namespace with the containers."
          info        : "https://docs.docker.com/reference/run/#pid-settings
2.http://man7.org/linux/man-pages/man7/pid_namespaces.7.html"
          solution    : "Do not start a container with '--pid=host' argument.For example, do not start a container as below-docker run --interactive --tty --pid=host centos /bin/bashImpact-Container processes cannot see the processes on the host system. In certain cases, you
want your container to share the host's process namespace. For example, you could build a
container with debugging tools like strace or gdb, but want to use these tools when
debugging processes within the container. If this is desired, then share only one (or
needed) host process by using the '-p' switch.For example,docker run --pid=host rhel7 strace -p 1234Default Value-By default, all containers have the PID namespace enabled and the host's process
namespace is not shared with the containers."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: PidMode={{ .HostConfig.PidMode }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.15 Do not share the host's process namespace"
          info        : "Process ID (PID) namespaces isolate the process ID number space, meaning that processes
in different PID namespaces can have the same PID. This is process level isolation between
containers and the host.PID namespace provides separation of processes. The PID Namespace removes the view of
the system processes, and allows process ids to be reused including PID 1. If the host's PID
namespace is shared with the container, it would basically allow processes within the
container to see all of the processes on the host system. This breaks the benefit of process
level isolation between the host and the containers. Someone having access to the
container can eventually know all the processes running on the host system and can even
kill the host system processes from within the container. This can be catastrophic. Hence,
do not share the host's process namespace with the containers."
          info        : "https://docs.docker.com/reference/run/#pid-settings
2.http://man7.org/linux/man-pages/man7/pid_namespaces.7.html"
          solution    : "Do not start a container with '--pid=host' argument.For example, do not start a container as below-docker run --interactive --tty --pid=host centos /bin/bashImpact-Container processes cannot see the processes on the host system. In certain cases, you
want your container to share the host's process namespace. For example, you could build a
container with debugging tools like strace or gdb, but want to use these tools when
debugging processes within the container. If this is desired, then share only one (or
needed) host process by using the '-p' switch.For example,docker run --pid=host rhel7 strace -p 1234Default Value-By default, all containers have the PID namespace enabled and the host's process
namespace is not shared with the containers."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: PidMode={{ .HostConfig.PidMode }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.16 Do not share the host's IPC namespace"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: IpcMode={{ .HostConfig.IpcMode }}'"
          expect      : "IpcMode=host"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.16 Do not share the host's IPC namespace"
          info        : "IPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments,
semaphores and message queues. IPC namespace on the host thus should not be shared
with the containers and should remain isolated.IPC namespace provides separation of IPC between the host and containers. If the host's
IPC namespace is shared with the container, it would basically allow processes within the
container to see all of the IPC on the host system. This breaks the benefit of IPC level
isolation between the host and the containers. Someone having access to the container can
eventually manipulate the host IPC. This can be catastrophic. Hence, do not share the host's
IPC namespace with the containers."
          info        : "https://docs.docker.com/reference/run/#ipc-settings
2.http://man7.org/linux/man-pages/man7/namespaces.7.html"
          solution    : "Do not start a container with '--ipc=host' argument.
For example, do not start a container as below-docker run --interactive --tty --ipc=host centos /bin/bashImpact-Shared memory segments are used to accelerate inter-process communication. It is
commonly used by high performance applications. If such applications are containerized
into multiple containers, you might need to share the IPC namespace of the containers to
achieve high performance. In such cases, you should still be sharing container specific IPC
namespaces only and not the host IPC namespace. You may share the container's IPC
namespace with other container as below-$> docker run <Run arguments> --ipc=container-$INSTANCE_ID <Container Image Name
or ID> <Command>For example,docker run --interactive --tty --ipc=container-e3a7a1a97c58 centos /bin/bashDefault Value-By default, all containers have the IPC namespace enabled and host IPC namespace is not
shared with any container."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: IpcMode={{ .HostConfig.IpcMode }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.16 Do not share the host's IPC namespace"
          info        : "IPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments,
semaphores and message queues. IPC namespace on the host thus should not be shared
with the containers and should remain isolated.IPC namespace provides separation of IPC between the host and containers. If the host's
IPC namespace is shared with the container, it would basically allow processes within the
container to see all of the IPC on the host system. This breaks the benefit of IPC level
isolation between the host and the containers. Someone having access to the container can
eventually manipulate the host IPC. This can be catastrophic. Hence, do not share the host's
IPC namespace with the containers."
          info        : "https://docs.docker.com/reference/run/#ipc-settings
2.http://man7.org/linux/man-pages/man7/namespaces.7.html"
          solution    : "Do not start a container with '--ipc=host' argument.
For example, do not start a container as below-docker run --interactive --tty --ipc=host centos /bin/bashImpact-Shared memory segments are used to accelerate inter-process communication. It is
commonly used by high performance applications. If such applications are containerized
into multiple containers, you might need to share the IPC namespace of the containers to
achieve high performance. In such cases, you should still be sharing container specific IPC
namespaces only and not the host IPC namespace. You may share the container's IPC
namespace with other container as below-$> docker run <Run arguments> --ipc=container-$INSTANCE_ID <Container Image Name
or ID> <Command>For example,docker run --interactive --tty --ipc=container-e3a7a1a97c58 centos /bin/bashDefault Value-By default, all containers have the IPC namespace enabled and host IPC namespace is not
shared with any container."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: IpcMode={{ .HostConfig.IpcMode }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.17 Do not directly expose host devices to containers"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Devices={{ .HostConfig.Devices }}'"
          expect      : "Devices=\\[.+\\]"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.17 Do not directly expose host devices to containers"
          info        : "Host devices can be directly exposed to containers at runtime. Do not directly expose host
devices to containers especially for containers that are not trusted.The '--device' option exposes the host devices to the containers and consequently the
containers can directly access such host devices. You would not require the container to
run in 'privileged' mode to access and manipulate the host devices. By default, the
container will be able to read, write and mknod these devices. Additionally, it is possible for
containers to remove block devices from the host. Hence, do not expose host devices to
containers directly.If at all, you would want to expose the host device to a container, use the sharing
permissions appropriately:. r - read only
. w - writable
. m - mknod allowed"
          info        : "http://docs.docker.com/reference/commandline/cli/#run"
          solution    : "Do not directly expose the host devices to containers. If at all, you need to expose the host
devices to containers, use the correct set of permissions-For example, do not start a container as below-docker run --interactive --tty --device=/dev/tty0-/dev/tty0-rwm --
device=/dev/temp_sda-/dev/temp_sda-rwm centos bashFor example, share the host device with correct permissions-docker run --interactive --tty --device=/dev/tty0-/dev/tty0-rw --
device=/dev/temp_sda-/dev/temp_sda-r centos bashImpact-You would not be able to use the host devices directly within the containers.Default Value-By default, no host devices are exposed to containers. If you do not provide sharing
permissions and choose to expose a host device to a container, the host device would be
exposed with read, write and mknod permissions."
          reference   : "800-171|3.13.4,800-53|SC-4,ITSG-33|SC-4,LEVEL|1NS"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Devices={{ .HostConfig.Devices }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.17 Do not directly expose host devices to containers"
          info        : "Host devices can be directly exposed to containers at runtime. Do not directly expose host
devices to containers especially for containers that are not trusted.The '--device' option exposes the host devices to the containers and consequently the
containers can directly access such host devices. You would not require the container to
run in 'privileged' mode to access and manipulate the host devices. By default, the
container will be able to read, write and mknod these devices. Additionally, it is possible for
containers to remove block devices from the host. Hence, do not expose host devices to
containers directly.If at all, you would want to expose the host device to a container, use the sharing
permissions appropriately:. r - read only
. w - writable
. m - mknod allowed"
          info        : "http://docs.docker.com/reference/commandline/cli/#run"
          solution    : "Do not directly expose the host devices to containers. If at all, you need to expose the host
devices to containers, use the correct set of permissions-For example, do not start a container as below-docker run --interactive --tty --device=/dev/tty0-/dev/tty0-rwm --
device=/dev/temp_sda-/dev/temp_sda-rwm centos bashFor example, share the host device with correct permissions-docker run --interactive --tty --device=/dev/tty0-/dev/tty0-rw --
device=/dev/temp_sda-/dev/temp_sda-r centos bashImpact-You would not be able to use the host devices directly within the containers.Default Value-By default, no host devices are exposed to containers. If you do not provide sharing
permissions and choose to expose a host device to a container, the host device would be
exposed with read, write and mknod permissions."
          reference   : "800-171|3.13.4,800-53|SC-4,ITSG-33|SC-4,LEVEL|1NS"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Devices={{ .HostConfig.Devices }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.18 Override default ulimit at runtime only if needed"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Ulimits={{json .HostConfig.Ulimits }}'"
          expect      : "Ulimits=\\[.*\\]"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.18 Override default ulimit at runtime only if needed"
          info        : "The default ulimit is set at the Docker daemon level. However, you may override the default
ulimit setting, if needed, during container runtime.ulimit provides control over the resources available to the shell and to processes started
by it. Setting system resource limits judiciously saves you from many disasters such as a
fork bomb. Sometimes, even friendly users and legitimate processes can overuse system
resources and in-turn can make the system unusable.The default ulimit set at the Docker daemon level should be honored. If the default ulimit
settings are not appropriate for a particular container instance, you may override them as
an exception. But, do not make this a practice. If most of the container instances are
overriding default ulimit settings, consider changing the default ulimit settings to
something that is appropriate for your needs."
          info        : "http://docs.docker.com/reference/commandline/cli/#setting-ulimits-in-a-container"
          solution    : "Only override the default ulimit settings if needed.For example, to override default ulimit settings start a container as below-docker run --ulimit nofile=1024-1024 --interactive --tty centos /bin/bashImpact-If the ulimits are not set properly, the desired resource control might not be achieved and
might even make the system unusable.
Default Value-Container instances inherit the default ulimit settings set at the Docker daemon level."
          reference   : "800-53|SC-6,CN-L3|7.1.3.7(c),CN-L3|7.1.3.7(d),ITSG-33|SC-6,LEVEL|1NS"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Ulimits={{json .HostConfig.Ulimits }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.18 Override default ulimit at runtime only if needed"
          info        : "The default ulimit is set at the Docker daemon level. However, you may override the default
ulimit setting, if needed, during container runtime.ulimit provides control over the resources available to the shell and to processes started
by it. Setting system resource limits judiciously saves you from many disasters such as a
fork bomb. Sometimes, even friendly users and legitimate processes can overuse system
resources and in-turn can make the system unusable.The default ulimit set at the Docker daemon level should be honored. If the default ulimit
settings are not appropriate for a particular container instance, you may override them as
an exception. But, do not make this a practice. If most of the container instances are
overriding default ulimit settings, consider changing the default ulimit settings to
something that is appropriate for your needs."
          info        : "http://docs.docker.com/reference/commandline/cli/#setting-ulimits-in-a-container"
          solution    : "Only override the default ulimit settings if needed.For example, to override default ulimit settings start a container as below-docker run --ulimit nofile=1024-1024 --interactive --tty centos /bin/bashImpact-If the ulimits are not set properly, the desired resource control might not be achieved and
might even make the system unusable.
Default Value-Container instances inherit the default ulimit settings set at the Docker daemon level."
          reference   : "800-53|SC-6,CN-L3|7.1.3.7(c),CN-L3|7.1.3.7(d),ITSG-33|SC-6,LEVEL|1NS"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "/usr/bin/docker ps -q | xargs /usr/bin/docker inspect --format '{{ .Id }}: Ulimits={{json .HostConfig.Ulimits }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.19 Do not set mount propagation mode to shared"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Propagation={{range $mnt := .Mounts}} {{json $mnt.Propagation}} {{end}}'"
          expect      : "shared"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.19 Do not set mount propagation mode to shared"
          info        : "Mount propagation mode allows mounting volumes in shared, slave or private mode on a
container. Do not use shared mount propagation mode until needed.A shared mount is replicated at all mounts and the changes made at any mount point are
propagated to all mounts. Mounting a volume in shared mode does not restrict any other
container to mount and make changes to that volume. This might be catastrophic if the
mounted volume is sensitive to changes. Do not set mount propagation mode to shared
until needed."
          info        : "https://github.com/docker/docker/pull/17034
2.https://docs.docker.com/engine/reference/run/
3.https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt"
          solution    : "Do not mount volumes in shared mode propagation.For example, do not start container as below-docker run <Run arguments> --volume=/hostPath-/containerPath-shared <Container Image
Name or ID> <Command>Impact-None.Default Value-By default, the container mounts are private."
          reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Propagation={{range $mnt := .Mounts}} {{json $mnt.Propagation}} {{end}}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.19 Do not set mount propagation mode to shared"
          info        : "Mount propagation mode allows mounting volumes in shared, slave or private mode on a
container. Do not use shared mount propagation mode until needed.A shared mount is replicated at all mounts and the changes made at any mount point are
propagated to all mounts. Mounting a volume in shared mode does not restrict any other
container to mount and make changes to that volume. This might be catastrophic if the
mounted volume is sensitive to changes. Do not set mount propagation mode to shared
until needed."
          info        : "https://github.com/docker/docker/pull/17034
2.https://docs.docker.com/engine/reference/run/
3.https://www.kernel.org/doc/Documentation/filesystems/sharedsubtree.txt"
          solution    : "Do not mount volumes in shared mode propagation.For example, do not start container as below-docker run <Run arguments> --volume=/hostPath-/containerPath-shared <Container Image
Name or ID> <Command>Impact-None.Default Value-By default, the container mounts are private."
          reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Propagation={{range $mnt := .Mounts}} {{json $mnt.Propagation}} {{end}}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.20 Do not share the host's UTS namespace"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: UTSMode={{ .HostConfig.UTSMode }}'"
          expect      : "host"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.20 Do not share the host's UTS namespace"
          info        : "UTS namespaces provide isolation of two system identifiers: the hostname and the NIS
domain name. It is used for setting the hostname and the domain that is visible to running
processes in that namespace. Processes running within containers do not typically require
to know hostname and domain name. Hence, the namespace should not be shared with the
host.Sharing the UTS namespace with the host provides full permission to the container to
change the hostname of the host. This is insecure and should not be allowed."
          info        : "https://docs.docker.com/engine/reference/run/
2.http://man7.org/linux/man-pages/man7/namespaces.7.html"
          solution    : "Do not start a container with '--uts=host' argument.For example, do not start a container as below-docker run --rm --interactive --tty --uts=host rhel7.2Impact-None.Default Value-
By default, all containers have the UTS namespace enabled and host UTS namespace is not
shared with any container."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: UTSMode={{ .HostConfig.UTSMode }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.20 Do not share the host's UTS namespace"
          info        : "UTS namespaces provide isolation of two system identifiers: the hostname and the NIS
domain name. It is used for setting the hostname and the domain that is visible to running
processes in that namespace. Processes running within containers do not typically require
to know hostname and domain name. Hence, the namespace should not be shared with the
host.Sharing the UTS namespace with the host provides full permission to the container to
change the hostname of the host. This is insecure and should not be allowed."
          info        : "https://docs.docker.com/engine/reference/run/
2.http://man7.org/linux/man-pages/man7/namespaces.7.html"
          solution    : "Do not start a container with '--uts=host' argument.For example, do not start a container as below-docker run --rm --interactive --tty --uts=host rhel7.2Impact-None.Default Value-
By default, all containers have the UTS namespace enabled and host UTS namespace is not
shared with any container."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: UTSMode={{ .HostConfig.UTSMode }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.21 Do not disable default seccomp profile"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }}'"
          expect      : "seccomp:unconfined"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.21 Do not disable default seccomp profile"
          info        : "Seccomp filtering provides a means for a process to specify a filter for incoming system
calls. The default Docker seccomp profile works on whitelist basis and allows 311 system
calls blocking all others. It should not be disabled unless it hinders your container
application usage.A large number of system calls are exposed to every userland process with many of them
going unused for the entire lifetime of the process. Most of the applications do not need all
the system calls and thus benefit by having a reduced set of available system calls. The
reduced set of system calls reduces the total kernel surface exposed to the application and
thus improvises application security."
          info        : "http://blog.scalock.com/new-docker-security-features-and-what-they-mean-seccomp-profiles
2.https://docs.docker.com/engine/reference/run/
3.https://github.com/docker/docker/blob/master/profiles/seccomp/default.json
4.https://docs.docker.com/engine/security/seccomp/
5.https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt"
          solution    : "By default, seccomp profiles are enabled. You do not need to do anything unless you want
to modify and use the modified seccomp profile.Impact-With Docker 1.10 and greater, the default seccomp profile blocks syscalls, regardless of --
cap-add passed to the container. You should create your own custom seccomp profile in
such cases. You may also disable the default seccomp profile by passing --security-
opt=seccomp-unconfined on docker run.
Default Value-When you run a container, it uses the default profile unless you override it with the --
security-opt option."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.21 Do not disable default seccomp profile"
          info        : "Seccomp filtering provides a means for a process to specify a filter for incoming system
calls. The default Docker seccomp profile works on whitelist basis and allows 311 system
calls blocking all others. It should not be disabled unless it hinders your container
application usage.A large number of system calls are exposed to every userland process with many of them
going unused for the entire lifetime of the process. Most of the applications do not need all
the system calls and thus benefit by having a reduced set of available system calls. The
reduced set of system calls reduces the total kernel surface exposed to the application and
thus improvises application security."
          info        : "http://blog.scalock.com/new-docker-security-features-and-what-they-mean-seccomp-profiles
2.https://docs.docker.com/engine/reference/run/
3.https://github.com/docker/docker/blob/master/profiles/seccomp/default.json
4.https://docs.docker.com/engine/security/seccomp/
5.https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt"
          solution    : "By default, seccomp profiles are enabled. You do not need to do anything unless you want
to modify and use the modified seccomp profile.Impact-With Docker 1.10 and greater, the default seccomp profile blocks syscalls, regardless of --
cap-add passed to the container. You should create your own custom seccomp profile in
such cases. You may also disable the default seccomp profile by passing --security-
opt=seccomp-unconfined on docker run.
Default Value-When you run a container, it uses the default profile unless you override it with the --
security-opt option."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.24 Confirm cgroup usage"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: CgroupParent={{ .HostConfig.CgroupParent }}'"
          expect      : "CgroupParent=.+"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.24 Confirm cgroup usage"
          info        : "It is possible to attach to a particular cgroup on container run. Confirming cgroup usage
would ensure that containers are running under defined cgroups.System administrators typically define cgroups under which containers are supposed to
run. Even if cgroups are not explicitly defined by the system administrators, containers run
under docker cgroup by default.At run-time, it is possible to attach to a different cgroup other than the one that was
expected to be used. This usage should be monitored and confirmed. By attaching to a
different cgroup than the one that is expected, excess permissions and resources might be
granted to the container and thus, can prove to be unsafe."
          info        : "https://docs.docker.com/engine/reference/run/#specifying-custom-cgroups
2.https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/ch01.html"
          solution    : "Do not use --cgroup-parent option in docker run command unless needed.Impact-None.Default Value-By default, containers run under docker cgroup."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: CgroupParent={{ .HostConfig.CgroupParent }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.24 Confirm cgroup usage"
          info        : "It is possible to attach to a particular cgroup on container run. Confirming cgroup usage
would ensure that containers are running under defined cgroups.System administrators typically define cgroups under which containers are supposed to
run. Even if cgroups are not explicitly defined by the system administrators, containers run
under docker cgroup by default.At run-time, it is possible to attach to a different cgroup other than the one that was
expected to be used. This usage should be monitored and confirmed. By attaching to a
different cgroup than the one that is expected, excess permissions and resources might be
granted to the container and thus, can prove to be unsafe."
          info        : "https://docs.docker.com/engine/reference/run/#specifying-custom-cgroups
2.https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/ch01.html"
          solution    : "Do not use --cgroup-parent option in docker run command unless needed.Impact-None.Default Value-By default, containers run under docker cgroup."
          reference   : "800-53|SC-39,LEVEL|1S"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: CgroupParent={{ .HostConfig.CgroupParent }}'"
          expect      : ".+"
        </custom_item>
      </else>
    </if>

    <custom_item>
      type        : CMD_EXEC
      description : "5.25 Restrict container from acquiring additional privileges"
      info        : "Restrict the container from acquiring additional privileges via suid or sgid bits.A process can set the no_new_priv bit in the kernel. It persists across fork, clone and
execve. The no_new_priv bit ensures that the process or its children processes do not gain
any additional privileges via suid or sgid bits. This way a lot of dangerous operations
become a lot less dangerous because there is no possibility of subverting privileged
binaries."
      info        : "https://github.com/projectatomic/atomic-site/issues/269
2.https://github.com/docker/docker/pull/20727
3.https://www.kernel.org/doc/Documentation/prctl/no_new_privs.txt
4.https://lwn.net/Articles/475678/
5.https://lwn.net/Articles/475362/"
      solution    : "Start a container as below-docker run <run-options> --security-opt=no-new-privileges <IMAGE> <CMD>For example,docker run --rm -it --security-opt=no-new-privileges ubuntu bashImpact-no_new_priv prevents LSMs like SELinux from transitioning to process labels that have
access not allowed to the current process.Default Value-By default, new privileges are not restricted."
      reference   : "800-53|SC-39,LEVEL|1S"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }}'|grep -v no-new-privileges"
      expect      : ""
    </custom_item>

    <custom_item>
      type        : CMD_EXEC
      description : "5.26 Check container health at runtime"
      info        : "If the container image does not have an HEALTHCHECK instruction defined, use --health-
cmd parameter at container runtime for checking container health.One of the important security triads is availability. If the container image you are using
does not have a pre-defined HEALTHCHECK instruction, use the --health-cmd parameter to
check container health at runtime.Based on the reported health status, you could take necessary actions."
      info        : "https://github.com/docker/docker/pull/22719
      NOTE: Nessus has provided the target output to assist in reviewing the benchmark to ensure target compliance."
      solution    : "Run the container using --health-cmd and the other parameters.For example,docker run -d --health-cmd='stat /etc/passwd || exit 1' nginxImpact-None.Default Value-By default, health checks are not done at container runtime."
      reference   : "800-171|3.4.2,800-53|CM-6,CN-L3|8.1.10.6(d),CSF|PR.IP-1,ITSG-33|CM-6,LEVEL|1S,NESA|T3.2.1,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Health={{ .State.Health.Status }}'"
      expect      : "Health="
      severity    : MEDIUM
    </custom_item>

    <report type:"WARNING">
      description : "5.27 Ensure docker commands always get the latest version of the image"
      info        : "Always ensure that you are using the latest version of the image within your repository and
not the cached older versions.Multiple docker commands such as docker pull, docker run, etc. are known to have an
issue that by default, they extract the local copy of the image, if present, even though there
is an updated version of the image with the 'same tag' in the upstream repository. This
could lead to using older and vulnerable images."
      info        : "https://github.com/docker/docker/pull/16609"
      solution    : "Use proper version pinning mechanisms (the latest tag which is assigned by default is still
vulnerable to caching attacks) to avoid extracting the cached older versions. Version
pinning mechanisms should be used for base images, packages, and entire images too. You
can customize version pinning rules as per your requirements.Impact-None
Default Value-By default, docker commands extract the local copy unless version pinning mechanisms are
used or the local cache is cleared.
NOTE: Nessus has not performed this check. Please review the benchmark to ensure target compliance."
      reference   : "LEVEL|1NS"
      see_also    : "https://workbench.cisecurity.org/files/517"
    </report>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.28 Use PIDs cgroup limit"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'"
          expect      : "PidsLimit=(0|-1)$"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.28 Use PIDs cgroup limit"
          info        : "Use --pids-limit flag at container runtime.Attackers could launch a fork bomb with a single command inside the container. This fork
bomb can crash the entire system and requires a restart of the host to make the system
functional again. PIDs cgroup --pids-limit will prevent this kind of attacks by restricting
the number of forks that can happen inside a container at a given time."
          info        : "https://github.com/docker/docker/pull/18697
2.https://docs.docker.com/engine/reference/commandline/run/"
          solution    : "Use --pids-limit flag while launching the container with an appropriate value.For example,docker run -it --pids-limit 100 <Image_ID>In the above example, the number of processes allowed to run at any given time is set to
100. After a limit of 100 concurrently running processes is reached, docker would restrict
any new process creation.Impact-Set the PIDs limit value as appropriate. Incorrect values might leave the containers
unusable.Default Value-The Default value for --pids-limit is 0 which means there is no restriction on the number
of forks. Also, note that PIDs cgroup limit works only for the kernel versions 4.3+."
          reference   : "800-53|SC-5,CSF|DE.CM-1,CSF|PR.DS-4,ITSG-33|SC-5,LEVEL|1S,NESA|T3.3.1,NIAv2|GS10c,NIAv2|GS8e"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.28 Use PIDs cgroup limit"
          info        : "Use --pids-limit flag at container runtime.Attackers could launch a fork bomb with a single command inside the container. This fork
bomb can crash the entire system and requires a restart of the host to make the system
functional again. PIDs cgroup --pids-limit will prevent this kind of attacks by restricting
the number of forks that can happen inside a container at a given time."
          info        : "https://github.com/docker/docker/pull/18697
2.https://docs.docker.com/engine/reference/commandline/run/"
          solution    : "Use --pids-limit flag while launching the container with an appropriate value.For example,docker run -it --pids-limit 100 <Image_ID>In the above example, the number of processes allowed to run at any given time is set to
100. After a limit of 100 concurrently running processes is reached, docker would restrict
any new process creation.Impact-Set the PIDs limit value as appropriate. Incorrect values might leave the containers
unusable.Default Value-The Default value for --pids-limit is 0 which means there is no restriction on the number
of forks. Also, note that PIDs cgroup limit works only for the kernel versions 4.3+."
          reference   : "800-53|SC-5,CSF|DE.CM-1,CSF|PR.DS-4,ITSG-33|SC-5,LEVEL|1S,NESA|T3.3.1,NIAv2|GS10c,NIAv2|GS8e"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <if>
      <condition type:"AND">
        <custom_item>
          type        : CMD_EXEC
          description : "5.30 Do not share the host's user namespaces"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: UsernsMode={{ .HostConfig.UsernsMode }}'"
          expect      : "UsernsMode=.+"
        </custom_item>
      </condition>

      <then>
        <custom_item>
          type        : CMD_EXEC
          description : "5.30 Do not share the host's user namespaces"
          info        : "Do not share the host's user namespaces with the containers.User namespaces ensure that a root process inside the container will be mapped to a non-
root process outside the container. Sharing the user namespaces of the host with the
container thus does not isolate users on the host with users on the containers."
          info        : "https://docs.docker.com/engine/reference/commandline/run/#/run
2.https://events.linuxfoundation.org/sites/events/files/slides/User%20Namespaces%20-%20ContainerCon%202015%20-%2016-9-final_0.pdf
3.https://github.com/docker/docker/pull/12648"
          solution    : "Do not share user namespaces between host and containers.Impact-NoneDefault Value-By default, the host user namespace is shared with the containers until user namespace
support is enabled."
          reference   : "800-171|3.13.1,800-171|3.13.5,800-53|SC-7,CN-L3|8.1.10.6(j),CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7,LEVEL|1S,NESA|T3.4.1,NESA|T3.6.3,NESA|T4.2.1,NESA|T4.3.1,NESA|T4.3.2,NESA|T4.5.1,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,TBA-FIISB|43.1"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: UsernsMode={{ .HostConfig.UsernsMode }}'"
          expect      : ""
        </custom_item>
      </then>

      <else>
        <custom_item>
          type        : CMD_EXEC
          description : "5.30 Do not share the host's user namespaces"
          info        : "Do not share the host's user namespaces with the containers.User namespaces ensure that a root process inside the container will be mapped to a non-
root process outside the container. Sharing the user namespaces of the host with the
container thus does not isolate users on the host with users on the containers."
          info        : "https://docs.docker.com/engine/reference/commandline/run/#/run
2.https://events.linuxfoundation.org/sites/events/files/slides/User%20Namespaces%20-%20ContainerCon%202015%20-%2016-9-final_0.pdf
3.https://github.com/docker/docker/pull/12648"
          solution    : "Do not share user namespaces between host and containers.Impact-NoneDefault Value-By default, the host user namespace is shared with the containers until user namespace
support is enabled."
          reference   : "800-171|3.13.1,800-171|3.13.5,800-53|SC-7,CN-L3|8.1.10.6(j),CSF|DE.CM-1,CSF|PR.AC-5,CSF|PR.DS-5,CSF|PR.PT-4,ISO/IEC-27001|A.13.1.3,ITSG-33|SC-7,LEVEL|1S,NESA|T3.4.1,NESA|T3.6.3,NESA|T4.2.1,NESA|T4.3.1,NESA|T4.3.2,NESA|T4.5.1,NESA|T4.5.4,NIAv2|GS1,NIAv2|GS2a,NIAv2|GS2b,TBA-FIISB|43.1"
          see_also    : "https://workbench.cisecurity.org/files/517"
          cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: UsernsMode={{ .HostConfig.UsernsMode }}'"
          expect      : ".*"
        </custom_item>
      </else>
    </if>

    <custom_item>
      type        : CMD_EXEC
      description : "5.31 Do not mount the Docker socket inside any containers"
      info        : "The docker socket (docker.sock) should not be mounted inside a container.If the docker socket is mounted inside a container it would allow processes running within
the container to execute docker commands which effectively allows for full control of the
host."
      info        : "https://raesene.github.io/blog/2016/03/06/The-Dangers-Of-Docker.sock/
2.https://forums.docker.com/t/docker-in-docker-vs-mounting-var-run-docker-
sock/9450/2
3.https://github.com/docker/docker/issues/21109"
      solution    : "Ensure that no containers mount docker.sock as a volume.Impact-NoneDefault Value-By default, docker.sock is not mounted inside containers."
      reference   : "800-171|3.4.6,800-171|3.4.7,800-53|CM-7,CN-L3|7.1.3.5(c),CN-L3|7.1.3.7(d),CN-L3|8.1.4.4(b),CSF|PR.IP-1,CSF|PR.PT-3,ITSG-33|CM-7,LEVEL|1S,NIAv2|SS13b,NIAv2|SS14a,NIAv2|SS14c,NIAv2|SS15a,SWIFT-CSCv1|2.3"
      see_also    : "https://workbench.cisecurity.org/files/517"
      cmd         : "docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Volumes={{ .Mounts }}' | grep docker\\.sock"
      expect      : ""
    </custom_item>

    <report type:"WARNING">
      description : "6.1 Perform regular security audits of your host system and containers"
      info        : "Perform regular security audits of your host system and containers to identify any mis-
configurations or vulnerabilities that could expose your system to compromise.Performing regular and dedicated security audits of your host systems and containers
could provide deep security insights that you might not know in your daily course of
business. The identified security weaknesses should be then mitigated and this overall
improves security posture of your environment."
      info        : "http://searchsecurity.techtarget.com/IT-security-auditing-Best-practices-for-conducting-audits
  NOTE: Nessus has not performed this check. Please review the benchmark to ensure target compliance."
      solution    : "Follow your organization's security audit policies and requirements.Impact-None.Default Value-Not applicable."
      reference   : "LEVEL|1S"
      see_also    : "https://workbench.cisecurity.org/files/517"
    </report>

    <report type:"WARNING">
      description : "6.2 Monitor Docker containers usage, performance and metering"
      info        : "Containers might run services that are critical for your business. Monitoring their usage,
performance and metering would be of paramount importance.Tracking container usage, performance and having some sort of metering around them
would be important as you embrace the containers to run critical services for your
business. This would give you. Capacity Management and Optimization
. Performance Management
. Comprehensive VisibilitySuch a deep visibility of container performance would help you ensure high availability of
containers and minimum downtime."
      info        : "https://docs.docker.com/articles/runmetrics/
2.https://github.com/google/cadvisor
3.https://docs.docker.com/reference/commandline/cli/#stats
NOTE: Nessus has not performed this check. Please review the benchmark to ensure target compliance."
      solution    : "Use a software or a container for tracking container usage, reporting performance and
metering.Impact-To get container metrics, you would have to utilize another container in privileged mode or
a software that can enter namespace of various containers. Giving unrestricted access to
namespaces of all the containers might be too risky.
Default Value-By default, for each container, runtime metrics about CPU, memory, and block I/O usage is
tracked by the system via enforcement of control groups (cgroups) as below-CPU - /sys/fs/cgroup/cpu/system.slice/docker-$INSTANCE_ID.scope/Memory - /sys/fs/cgroup/memory/system.slice/docker-$INSTANCE_ID.scope/
Block I/O - /sys/fs/cgroup/blkio/system.slice/docker-$INSTANCE_ID.scope/"
      reference   : "LEVEL|1NS"
      see_also    : "https://workbench.cisecurity.org/files/517"
    </report>

    <report type:"WARNING">
      description : "6.3 Backup container data"
      info        : "Take regular backups of your container data volumes.Containers might run services that are critical for your business. Taking regular
data backups would ensure that if there is ever any loss of data you would still have your
data in backup. The loss of data could be devastating for your business."
      info        : "http://docs.docker.com/userguide/dockervolumes/#backup-restore-or-migrate-data-volumes
2.http://stackoverflow.com/questions/26331651/back-up-docker-container-that-has-a-volume
3.http://docs.docker.com/reference/commandline/cli/#diff
NOTE: Nessus has not performed this check. Please review the benchmark to ensure target compliance."
      solution    : "You should follow your organization's policy for data backup. You can take backup of your
container data volume using '--volumes-from' parameter as below-$> docker run <Run arguments> --volumes-from $INSTANCE_ID -v [host-dir]-[container-
dir] <Container Image Name or ID> <Command>For example,docker run --volumes-from 699ee3233b96 -v /mybackup-/backup centos tar cvf
/backup/backup.tar /exampledatatobackupImpact-None.
Default Value-By default, no data backup happens for container data volumes."
      reference   : "LEVEL|1NS"
      see_also    : "https://workbench.cisecurity.org/files/517"
    </report>
  </then>

  <else>
    <report type:"WARNING">
      description : "CIS_Docker_1.12.0_v1.0.0_L1.audit Level 1"
      info        : "NOTE: Nessus has not identified that the chosen audit applies to the target device."
      see_also    : "https://workbench.cisecurity.org/files/517"
    </report>
  </else>
</if>

</check_type>
